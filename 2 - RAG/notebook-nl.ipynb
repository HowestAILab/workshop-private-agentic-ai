{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c8e051",
   "metadata": {},
   "source": [
    "# **Retrieval Augmented Generation**\n",
    "\n",
    "_Taalmodellen zijn heel krachtig, maar zijn qua kennis gelimiteerd tot hun trainingdata en kunnen halucineren. De antwoorden zijn niet gestaafd door een bronvermelding. Vragen over onze eigen documenten kan deze ook niet zomaar beantwoorden. Dit is waar Retrieval Augmented Generation (RAG) een oplossing biedt. Het is een techniek waarbij we onze eigen documenten kunnen bevragen met natuurlijke taal._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bbed3",
   "metadata": {},
   "source": [
    "<img src=\"../.github/rag.png\" alt=\"RAG\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32984f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b915dec",
   "metadata": {},
   "source": [
    "## **Voorbereiding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31b98210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymilvus[model] pypdf ollama --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0827b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786e678",
   "metadata": {},
   "source": [
    "## **Embedder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e16eedb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elke vector zal uit 768 kommagetallen bestaan.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "\n",
    "# Laadt een standaard embedder model\n",
    "embedder = model.DefaultEmbeddingFunction()\n",
    "\n",
    "print(f\"Elke vector zal uit {embedder.dim} kommagetallen bestaan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8723d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103cebed",
   "metadata": {},
   "source": [
    "## **Vector database**\n",
    "\n",
    "Zoals verteld tijdens de theorie, hebben we een **vector database** nodig om onze documenten in op te slaan.\n",
    "\n",
    "\n",
    "Dit kan op verschillende manieren:\n",
    "\n",
    "| Opslagmethode     | Gebruik                   |\n",
    "|-------------------|---------------------------|\n",
    "| ‚òÅÔ∏è Cloud             | Productie                 |\n",
    "| üêã Docker container  | Productie (eigen server)  |\n",
    "| üìÅ Lokaal bestand    | Development               |\n",
    "| üïì In-memory         | Development               |\n",
    "\n",
    "Wij gaan **Milvus** gebruiken, een open-source vector database.<br>\n",
    "Net zoals Ollama, kan je Milvus zowel via een CLI als via Python aanspreken.<br>\n",
    "Naast Milvus zijn er tal van andere opties beschikbaar zoals Chroma, Qdrant, Vespa, (Pinecone, Weaviate) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace559d",
   "metadata": {},
   "source": [
    "### **1. Verbinden met / aanmaken van vector database**\n",
    "\n",
    "Typisch zou dit er ongeveer zo uitzien:\n",
    "\n",
    "```py\n",
    "vectordb = MilvusClient(uri=\"http://localhost:19530\", username=\"admin\", password=\"password\")\n",
    "```\n",
    "\n",
    "Wij hebben geen online database die ergens draait en toegankelijk is via een URL. <br>\n",
    "In plaats daarvan gaan we een **lokaal bestand** aanmaken dat we kunnen gebruiken als database.<br>\n",
    "Als het bestand niet bestaat, dan wordt het automatisch aangemaakt, handig!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5ed4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "vectordb = MilvusClient(\"../milvus.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abefe972",
   "metadata": {},
   "source": [
    "Met het client object `vectordb` kunnen we nu d.m.v. Python code interageren met de Milvus database:\n",
    "- `vectordb.create_user(...)`\n",
    "- `vectordb.create_collection(...)`\n",
    "- `vectordb.insert(...)`\n",
    "- `vectordb.query(...)`\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ada22",
   "metadata": {},
   "source": [
    "### **2. Maak een collectie aan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ce0c8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beschikbare collecties: blogpost\n"
     ]
    }
   ],
   "source": [
    "collections = vectordb.list_collections()\n",
    "\n",
    "if \"blogpost\" not in collections:\n",
    "  # Aanmaken van nieuwe collectie\n",
    "  vectordb.create_collection(\n",
    "    collection_name=\"blogpost\",\n",
    "    dimension=embedder.dim\n",
    "  )\n",
    "\n",
    "# Lijst alle collecties op ter controle\n",
    "collections = vectordb.list_collections()\n",
    "print(f\"Beschikbare collecties: {', '.join(collections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb73419",
   "metadata": {},
   "source": [
    "### **3. Uitlezen van PDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc455af",
   "metadata": {},
   "source": [
    "<img src=\"../.github/tekst-extractie.png\" alt=\"Tekst extractie\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83f048",
   "metadata": {},
   "source": [
    "Nu we onze vector database hebben aangemaakt, kunnen we beginnen met het toevoegen van documenten. <br>\n",
    "We gaan een PDF inlezen, omzetten naar vectoren en deze toevoegen aan de database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54374fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def lees_pdf(path):\n",
    "    # Open de PDF\n",
    "    pdf = PdfReader(path)\n",
    "    text = \"\"\n",
    "    # Overloop elke pagina\n",
    "    for page in pdf.pages:\n",
    "        # Lees de paginatekst uit\n",
    "        page_text = page.extract_text()\n",
    "        # Voeg de paginatekst toe aan de totale tekst\n",
    "        text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4ec28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blogpost\n",
      "Hoe maak je AI-modellen klein en \n",
      "effici√´nt?\n",
      "AI-modellen worden steeds krachtiger, maar vaak ook steeds groter. Grote \n",
      "modellen vereisen veel rekenkracht, geheugen en energie - wat ze minder \n",
      "geschikt maakt voor gebruik op edge devices, maar ook realtime computervisie \n",
      "applicaties zoals de Howest Virtual Mirror. Gelukkig zijn er diverse technieken \n",
      "om AI-modellen te verkleinen zonder de accuraatheid ervan te verlagen. In \n",
      "deze blogpost bespreken we de belangrijkste optimalisatiestrategie√´n: \n",
      "quantisatie, distillatie, pruning en meer. We bekijken ook welke tools je kunt \n",
      "gebruiken, op welke platformen ze draaien, en hoe groot de impact kan zijn.\n",
      "1. Quantisatie\n",
      "Inleiding\n",
      "Binnenin een AI model zitten er miljoenen tot miljarden kommagetallen - ook \n",
      "wel ‚ÄúgewichtenÀÆ en ‚ÄúactivatiesÀÆ genoemd. Elk getal neemt typisch 32 bits \n",
      "(nullen en enen) geheugen in beslag.\n",
      "Voor een computer zijn kommagetallen eigenlijk zeer lastig om mee te rekenen. \n",
      "√â√©n zo ºn berekening duurt uiteraard slechts enkele nanoseconden (of minder), \n",
      "maar door de enorme hoeveelheid ervan loopt deze vertraging zo hoog op dat \n",
      "het uiteindelijke model er seconden tot minuten over doet om data te \n",
      "verwerken.\n",
      "Voorbeeld: elk sub-woord dat door GPTÓÇà4 genereert wordt moet door 1 tot 2 \n",
      "biljoen parameters verwerkt worden. Beeld je maar in hoeveel berekeningen \n",
      "nodig zijn om een volledige tekst te genereren. Dit is de reden dat er voor AI \n",
      "zo ºn grote nood is aan krachtige GPU ºs.\n",
      "Bestaand model quantiseren\n",
      "Post-training quantization ÓÇÅPTQÓÇÇ is het proces waarbij de getallen in een reeds \n",
      "getraind model worden omgezet van 32-bit floating-point ÓÇÅFP32ÓÇÇ naar een \n",
      "lagere precisie, zoals 16-bit ÓÇÅFP16ÓÇÇ of zelfs 8-bit integers ÓÇÅINT8ÓÇÇ. Concreet heb \n",
      "Blogpost\n",
      "1\n",
      "je dan minder cijfers na de komma, of zelfs helemaal geen kommagetallen \n",
      "meer.\n",
      "Impact:\n",
      "Tot 4x verkleining van modelgrootte (van FP32 naar INT8ÓÇÇ.\n",
      "2x tot 4x snelheidsverbetering.\n",
      "Vaak minimaal verlies in nauwkeurigheid ÓÇÅÓÇ°5%ÓÇÇ.\n",
      "Wat men vaak doet is het gequantiseerde model nog eens kort hertrainen of \n",
      "finetunen met gequantiseerde data. Dikwijls verhoogt dit de accuraatheid \n",
      "opnieuw naar het oorspronkelijke niveau van het niet-gequantiseerde model.\n",
      "Gequantiseerd trainen\n",
      "Een tweede mogelijkheid is Quantized Aware Training ÓÇÅQATÓÇÇ. Hierbij traint men \n",
      "het model met reeds afgeronde getallen om het quantisatie-effect te simuleren. \n",
      "Typisch levert dit nog betere resultaten op dan PTQ, maar je moet het op \n",
      "voorhand in rekening brengen of je model volledig hertrainen.\n",
      "Voorbeelden: op Ollama kan je van sommige taalmodellen - zoals de gemma3 \n",
      "familie - ook QAT-varianten terugvinden die tot 3 keer sneller zijn \n",
      "(https://ollama.com/library/gemma3ÓÇí4b-it-qat). Ook van computervisie \n",
      "modellen zoals YOLO bestaan PTQ-varianten zoals YOLOv8ÓÇàDetection-\n",
      "Quantized (https://huggingface.co/qualcomm/YOLOv8ÓÇàDetection-Quantized).\n",
      "Frameworks\n",
      "Er bestaan verschillende Python-libraries die functies bevatten om jouw model \n",
      "te quantiseren:\n",
      "Gebruik de ‚Äútf.lite.OptimizeÀÆ library voor TensorFlow modellen.\n",
      "Blogpost\n",
      "2\n",
      "Gebruik de ‚Äútorch.ao.quantizationÀÆ library voor PyTorch modellen. Dit is een \n",
      "onderdeel van de PyTorch Architecture Optimization library.\n",
      "Gebruik ‚Äúonnxruntime.quantizationÀÆ library voor modellen die ge√´xporteerd \n",
      "zijn als een gestandaardiseerd ONNX formaat.\n",
      "Ook Hugging Face ºs Optimum library beschikt over quantisatie \n",
      "mogelijkheden voor ONNX modellen en Intel-systemen.\n",
      "2. Pruning\n",
      "Pruning verwijdert elementen uit het model die weinig bijdragen aan het \n",
      "uiteindelijke resultaat ervan. Het verminderen van overbodige parameters \n",
      "verkleint het aantal berekeningen die moeten gemaakt worden waardoor het \n",
      "model sneller zal zijn.\n",
      "Er bestaan twee soorten pruning:\n",
      "Niet-gestructureerde pruning: verwijderen van individuele gewichten of \n",
      "verbindingen.\n",
      "Gestructureerde pruning: verwijderen van hele filters, neuronen of lagen.\n",
      "Blogpost\n",
      "3\n",
      "Ook hier kan je het model hertrainen of finetunen na het prunen om het kleine \n",
      "verlies in accuraatheid te compenseren.\n",
      "Frameworks\n",
      "Er bestaan Python-libraries die functies bevatten om jouw model te prunen:\n",
      "Gebruik de ‚Äútorch.nn.utils.pruneÀÆ library voor PyTorch modellen.\n",
      "Gebruik de ‚Äútensorflow_model_optimization.sparsity.kerasÀÆ library voor \n",
      "TensorFlow modellen.\n",
      "Ook Hugging Face ºs Optimum library beschikt over pruning mogelijkheden \n",
      "voor Intel-systemen.\n",
      "3. Kennisdistillatie\n",
      "Kennisdistillatie is een techniek waarbij een klein model wordt getraind om de \n",
      "output van een groot, krachtig model te imiteren. Men beschrijft dit vaak als \n",
      "een student-leerkracht relatie.\n",
      "Het leerkracht-model werd getraind door te leren uit grote hoeveelheden data. \n",
      "Het student-model daarentegen, wordt enkel getraind wordt op de output van \n",
      "een (reeds getraind) leerkracht-model en komt eigenlijk nooit in aanraking met \n",
      "de oorspronkelijke data.\n",
      "In de praktijk blijkt dat student-modellen vaak bijna dezelfde nauwkeurigheid \n",
      "kunnen bereiken als het leerkracht-model terwijl ze veel kleiner en sneller zijn. \n",
      "Voorbeeld: Het Chinese DeepSeek ontwikkelt gedistilleerde taalmodellen aan \n",
      "zoals DeepSeek-R1ÓÇàDistill-Qwen-7B (https://huggingface.co/deepseek-\n",
      "ai/DeepSeek-R1ÓÇàDistill-Qwen-7BÓÇÇ. Een ouder succesverhaal van distillatie is \n",
      "TinyBERT. Die is ruim 7 keer kleiner en 9 keer sneller dan het oorspronkelijke \n",
      "BERT terwijl het slecht een daling van ¬±3% heeft in nauwkeurigheid \n",
      "(https://arxiv.org/pdf/1909.10351ÓÇÇ.\n",
      "Samenvatting\n",
      "Blogpost\n",
      "4\n",
      "Optimalisatietechnieken kunnen een sterk voordeel bieden op vlak van \n",
      "snelheid, energieconsumptie, kostprijs, hardware beperkingen en speelt een \n",
      "grote rol in computervisie en taalmodellen. Het vergt wel enige tijd om mee te \n",
      "experimenteren en het verlies in accuraatheid te beoordelen en/of te \n",
      "compenseren. Deze extra ontwikkelingstijd kan afhankelijk van de schaal van \n",
      "het project wel of niet de moeite waard zijn. Of de implementatie van √©√©n of \n",
      "meerdere van deze technieken interessant is, moet dus voor elk scenario \n",
      "individueel beoordeeld worden.\n",
      "Samenvatting\n",
      "Optimalisatietechnieken zoals quantisatie, pruning en distillatie kunnen heel \n",
      "voordelig zijn op vlak van snelheid, energieverbruik, kostprijs en hardware-\n",
      "eisen. Zeker in toepassingen zoals computervisie en taalmodellen maken ze het \n",
      "verschil.\n",
      "Het vergt wel enige tijd om mee te experimenteren en het verlies in \n",
      "accuraatheid te beoordelen en/of te compenseren. Deze extra ontwikkelingstijd \n",
      "kan afhankelijk van de schaal van het project al dan niet de moeite waard zijn.\n",
      "Blogpost\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = lees_pdf(\"Blogpost.pdf\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b26fdc",
   "metadata": {},
   "source": [
    "### **4. Tekst opsplitsen in chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ee014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verdeel_in_chunks(text):\n",
    "    # Kap de tekst in stukken van 512 karakters met een overlap van 128 karakters\n",
    "    return [text[i:i+512] for i in range(0, len(text), 512-128)]\n",
    "\n",
    "chunks = verdeel_in_chunks(text)\n",
    "\n",
    "print(f\"De tekst van {len(text)} karakters is opgedeeld in {len(chunks)} stukken van 512 karakters met een overlap van 128 karakters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8df0f5",
   "metadata": {},
   "source": [
    "### **5. Chunks omzetten naar vectoren (embedding)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82583e",
   "metadata": {},
   "source": [
    "<img src=\"../.github/tekst-embedding.png\" alt=\"Tekst embedding\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed09b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.29018397e-02  3.39037056e-02  1.38407705e-02 -2.37033750e-02\n",
      "  1.41432738e-02  3.95084573e-03  1.88760994e-02 -8.68979462e-03\n",
      "  1.15502403e-02 -5.03735965e-02  2.82360528e-02  1.72524620e-02\n",
      " -4.01088364e-02 -9.24565788e-02  4.08351003e-03  8.70586708e-03\n",
      " -4.49316399e-02 -2.97982155e-02  9.14868732e-03 -3.51780520e-02\n",
      " -2.84741317e-02  7.10664068e-03  6.14569991e-03 -4.83656797e-02\n",
      " -1.91956371e-02  2.58579654e-02 -2.50019176e-03  6.60994206e-03\n",
      " -2.69456916e-02 -6.56962520e-03 -6.13001482e-02 -1.31405158e-02\n",
      " -1.11234524e-03 -1.92446541e-02 -5.01197160e-02 -5.89044375e-02\n",
      " -4.28711448e-03  1.35903676e-02 -1.09149342e-02  4.75778749e-02\n",
      " -1.04830449e-02  1.61411409e-02  5.04271557e-03  9.73946011e-02\n",
      " -1.69800678e-02  4.72020984e-02  3.78694586e-02 -1.64446858e-02\n",
      " -3.84101321e-02 -4.90670064e-02  5.57477220e-02 -2.05239546e-02\n",
      " -1.50153661e-02  2.02639093e-02 -3.07706504e-02  1.58992888e-02\n",
      "  2.00894465e-02 -5.43083171e-02  1.18508442e-02 -2.68718704e-02\n",
      "  1.21450267e-02 -2.39214409e-02  5.86705900e-02 -3.61095760e-02\n",
      " -4.11704393e-02 -3.05174746e-02  3.14643562e-02 -5.15372869e-02\n",
      "  2.54327067e-02 -8.62432474e-03 -2.84373588e-02 -4.64107920e-02\n",
      " -8.60515502e-03  6.41534523e-03  1.77646805e-02 -2.75246555e-02\n",
      "  4.05787941e-02  6.93191224e-02 -3.40865088e-02  9.66285353e-03\n",
      " -1.27230790e-02 -5.14471577e-04 -1.10420833e-02 -1.30841580e-02\n",
      " -7.23763181e-03  4.86812384e-02  1.81783370e-02  7.78857813e-03\n",
      " -6.80205300e-03  1.52834512e-02 -2.06837736e-02  1.52569340e-03\n",
      "  7.51989372e-03  3.27629697e-02  1.93539641e-02  8.12509284e-04\n",
      "  4.93492356e-04 -2.83715774e-02  2.21216301e-02 -1.22368625e-02\n",
      "  4.53555150e-02  1.50839244e-02 -4.37312473e-02  7.89725819e-02\n",
      " -6.86880269e-03  2.99914342e-02 -5.21590935e-02 -2.67936480e-03\n",
      " -3.26215990e-02  3.24733189e-02  7.62745810e-03 -1.53997838e-03\n",
      " -3.05134963e-02  1.30945189e-02 -6.00476900e-02  3.37007080e-02\n",
      " -3.51591675e-02 -6.14176502e-02  2.00682581e-02 -1.25138245e-02\n",
      "  1.15944293e-03 -8.69020606e-02  1.35035303e-01 -4.77658912e-02\n",
      "  6.81348792e-02  5.69250374e-02  1.98505585e-02 -7.60722262e-03\n",
      "  3.63328308e-02  1.21665211e-02 -6.67122343e-02  4.37948348e-02\n",
      "  5.58630633e-02  4.36157114e-02 -1.56763138e-02  5.46735590e-03\n",
      "  1.05680826e-02  1.12618790e-02 -1.25880984e-02  6.15648692e-02\n",
      " -4.00706519e-02  9.54690200e-03 -1.05000970e-02  2.54885264e-02\n",
      "  7.73917935e-03 -6.76430987e-03 -1.45775680e-02  1.14924083e-02\n",
      " -3.32918839e-02  7.25952227e-02  1.55882052e-03  3.15254819e-02\n",
      " -9.05846258e-03  3.28092457e-02 -2.47797608e-02  2.11368854e-02\n",
      "  4.17592061e-02  3.79725679e-02  4.03129617e-03  2.75199676e-02\n",
      " -3.64364591e-02 -3.67049691e-02 -5.00097429e-03  6.43647737e-03\n",
      "  4.01844290e-02  1.97040534e-02  1.29161155e-02 -4.40828720e-02\n",
      " -2.47980348e-02 -1.01318725e-02 -1.97954234e-02 -8.04329508e-03\n",
      " -1.37253653e-02  3.52287083e-02  4.40125992e-02  1.96309773e-02\n",
      " -2.21114602e-02  2.74205803e-02 -3.85074843e-02  2.47454651e-02\n",
      " -1.53780651e-02 -6.54478569e-02 -4.10286483e-04 -4.17411555e-02\n",
      " -1.08633394e-01 -2.34191794e-02  1.19084104e-02  5.77869606e-02\n",
      "  3.01943383e-02  1.14006947e-02 -1.21524627e-02 -1.65398443e-02\n",
      "  4.46837468e-02 -9.82887756e-02 -5.10967271e-02 -1.47878490e-03\n",
      "  7.57362598e-02  4.69748042e-02  1.21585478e-02 -1.21653979e-02\n",
      " -3.57738625e-02  3.29982519e-02 -2.47575667e-02 -4.74902478e-03\n",
      " -1.38650750e-02  3.54024461e-02 -1.02741380e-02 -1.83970390e-02\n",
      "  3.50892988e-02  2.27800753e-02  4.85937270e-02  4.19493760e-02\n",
      "  5.58204782e-03  2.01270565e-02  8.64438015e-02  4.27830522e-02\n",
      " -1.15271825e-02  5.30562089e-02 -4.99152006e-02  1.07081013e-02\n",
      "  1.08904745e-02  4.48052311e-02 -2.48611720e-02 -2.67264195e-02\n",
      " -3.80678703e-03  1.71548398e-03 -2.92502700e-02  6.40728445e-02\n",
      " -2.41556937e-02 -3.11177884e-04  1.61926448e-02  2.48861372e-02\n",
      "  4.19413723e-02  6.29891057e-02 -1.10093441e-02 -2.41922991e-02\n",
      "  7.26950772e-02 -1.76693471e-03 -3.97130998e-02 -2.19562446e-02\n",
      " -5.26816214e-02  7.77820383e-03  2.81375160e-02 -3.78988594e-02\n",
      "  5.55995866e-02  3.70276364e-03 -2.19400739e-02  9.07304303e-04\n",
      "  2.45818895e-02 -6.56266772e-02 -6.62461857e-02 -5.41731520e-02\n",
      "  1.91269850e-03  1.48637377e-02 -3.73244228e-02  1.26515863e-03\n",
      "  1.25810126e-02 -4.28534817e-02 -3.76794547e-02 -4.60391561e-02\n",
      " -9.69605009e-03 -1.13203993e-02 -3.89260357e-02  3.90191477e-02\n",
      " -4.40297619e-03  3.69700165e-02  2.31314405e-02  8.04737922e-03\n",
      " -2.76821069e-02  3.86876640e-02  1.25967881e-02 -4.11340576e-02\n",
      " -3.67877122e-02 -5.35488201e-02 -3.00374346e-02  1.45131152e-02\n",
      " -3.95472419e-03  6.24235763e-03 -4.83149490e-02 -4.24798631e-02\n",
      " -5.16404957e-02  1.63635523e-02  2.71407838e-03 -1.65586343e-02\n",
      "  4.04042677e-02  1.35038332e-03 -2.55763021e-02 -7.62204117e-02\n",
      "  1.60973095e-02 -4.45756308e-02 -5.77564455e-02  9.59892595e-03\n",
      " -5.88999536e-02 -2.64320195e-02 -1.58739145e-02  3.83749359e-02\n",
      "  6.19639489e-02  1.38845983e-02  3.32050251e-02 -5.84684713e-02\n",
      "  5.86367748e-02  2.68323391e-02 -1.39255792e-04 -6.82403229e-02\n",
      "  9.68132195e-03  4.86460382e-02 -3.41996337e-02 -4.33379283e-02\n",
      " -2.36026014e-02  1.86529355e-02 -2.01815391e-02 -2.61617870e-02\n",
      "  2.63423422e-02 -3.78661405e-03  2.38670811e-02  1.80422416e-02\n",
      "  2.43591072e-02 -3.15434479e-02 -2.34681553e-02  4.10473149e-02\n",
      " -4.64214771e-02 -3.16246082e-02 -4.60287435e-02  2.41655795e-02\n",
      " -7.02496929e-02  5.75260597e-03  3.10377126e-03  1.86515834e-03\n",
      " -1.13490785e-02  4.51385085e-02 -2.75052050e-02  3.81217402e-02\n",
      " -3.77473263e-02 -3.66991344e-02  1.94617191e-03  1.01533845e-02\n",
      " -2.88501737e-02  2.53184682e-02  5.28403477e-02  5.48570795e-02\n",
      " -1.04051184e-02  8.35227833e-03 -4.05000126e-02 -3.95726695e-02\n",
      "  4.37915236e-02 -2.58229248e-02 -1.95882881e-03 -1.83181555e-02\n",
      " -2.56138640e-03 -2.53897127e-02 -1.72105168e-02 -8.54047770e-03\n",
      " -4.00735579e-02  4.68037381e-02 -2.34592568e-02 -1.05757919e-02\n",
      " -7.49958032e-03  9.38533688e-03  5.57300350e-03  5.91945498e-02\n",
      " -3.77700767e-02  6.20723192e-03 -2.32309286e-02  3.66549960e-02\n",
      " -1.23853475e-02  2.65349025e-03 -4.46967565e-02 -1.44165243e-02\n",
      "  3.64262922e-02  7.57420319e-03 -1.98008074e-02  1.14977852e-03\n",
      "  2.31119857e-02 -6.65778013e-02 -5.98554028e-02 -9.08710652e-03\n",
      "  1.10994123e-02 -9.71615762e-02 -5.51877171e-02 -2.02556562e-02\n",
      "  3.58096804e-02  3.18187996e-02  1.27822766e-02  1.94794535e-02\n",
      " -4.82594395e-02  3.16822664e-02 -1.32055573e-02 -4.06359127e-02\n",
      "  6.86017598e-04  7.97978804e-03 -2.64326628e-02  1.21449789e-02\n",
      " -3.33198039e-02 -5.98141676e-03 -7.00149641e-03  1.40364071e-02\n",
      "  1.05124233e-03 -3.78792955e-02  4.33167211e-02  5.35643284e-02\n",
      "  4.45757675e-02  1.78363158e-02 -6.43025089e-02  3.28013031e-02\n",
      "  6.20182767e-03  6.77320361e-02  9.11664640e-03 -2.18719166e-02\n",
      " -1.52722451e-02 -1.24787344e-02 -1.25167368e-02  5.18947463e-02\n",
      " -5.53068999e-02  9.60374656e-03 -2.46697026e-03  6.41778004e-03\n",
      "  3.62028011e-02 -4.56352521e-02  2.57600068e-02 -2.75610399e-02\n",
      "  8.67469527e-02  1.01250042e-02  1.90956104e-02  2.97375094e-02\n",
      "  1.17174336e-02  3.27926836e-02  1.93980950e-02 -4.27530580e-02\n",
      "  4.19917973e-03 -4.09885493e-02  6.39165899e-03  1.97633775e-02\n",
      " -1.51605290e-02 -4.14404631e-02 -3.02595608e-02  3.94182831e-02\n",
      "  9.79193409e-03 -3.08853587e-02  4.45985993e-03  6.02621708e-04\n",
      "  1.89497477e-02  1.21336624e-02 -4.21404678e-02  1.69857135e-02\n",
      "  7.96656935e-02  1.87562792e-02 -5.21486572e-02 -1.58418525e-02\n",
      " -9.74471182e-03  2.95155776e-02 -5.56861654e-02  1.74495435e-02\n",
      " -7.02930017e-02 -6.29441203e-02  1.23776773e-02 -7.88001642e-02\n",
      " -2.12429289e-02  4.48197449e-02  4.46453050e-02  2.56537398e-02\n",
      " -7.60093255e-02  3.99727746e-02 -5.08371787e-02  5.21552974e-02\n",
      " -2.93499406e-02 -3.92394404e-02 -2.28575742e-02  7.85528940e-03\n",
      "  2.06884599e-02 -2.22027113e-02 -3.49985884e-02  2.00427241e-02\n",
      "  2.24220496e-02 -2.52052537e-02 -3.55581930e-03  1.20038393e-02\n",
      "  1.68657203e-02  3.18015654e-02  7.01911974e-02 -2.88399430e-03\n",
      "  3.42543497e-02 -2.77589823e-02 -2.71129956e-02  1.79851828e-02\n",
      " -1.48446037e-02  2.91109891e-02  5.03921723e-03 -1.34103680e-02\n",
      "  9.38122324e-02  5.77374830e-02  1.44390009e-02 -2.99785669e-02\n",
      "  1.60231615e-02 -2.91537258e-03 -1.03215370e-02  6.58704927e-03\n",
      "  2.77996662e-03 -5.23082024e-02 -1.62719500e-02  3.78938257e-02\n",
      "  9.88574292e-02  1.35627597e-02  4.05806237e-02  3.71762628e-03\n",
      "  3.27437085e-02 -4.65115256e-02 -1.64752534e-02  7.08357477e-02\n",
      " -2.02308636e-02 -8.19607098e-03  3.89378589e-02 -9.17030469e-04\n",
      "  6.46735103e-02  2.47894542e-02 -3.49180297e-02 -7.35774498e-02\n",
      "  3.54211826e-02 -7.97761273e-04 -6.07050917e-02  3.12786474e-02\n",
      "  6.41713066e-02  1.35825684e-03 -3.92977693e-03  2.34592040e-03\n",
      " -1.80077311e-03 -1.25613957e-02 -3.07518668e-02 -2.02449219e-02\n",
      "  4.66298869e-02 -3.31203167e-02 -4.35009539e-03 -4.43886646e-02\n",
      "  3.62026785e-02  5.10123639e-04  3.83664057e-02  2.31143211e-02\n",
      "  3.74994176e-02  6.68608936e-04 -7.58827870e-03  3.46811406e-02\n",
      " -3.86117961e-02 -1.08467948e-02  8.33794914e-02 -3.22930169e-02\n",
      "  2.29362493e-02 -5.02495355e-02 -1.91227995e-02  2.89755138e-02\n",
      " -4.21529768e-02 -2.80794464e-02  1.99666450e-02  3.35532220e-02\n",
      "  1.48460150e-02 -3.93938897e-02  2.58254169e-02  3.03234477e-02\n",
      "  1.69936621e-02 -3.32680905e-02  5.87104757e-05  3.90060542e-03\n",
      "  2.59776522e-02 -1.25538342e-02 -1.03383805e-01  8.38827587e-03\n",
      "  1.52882256e-03  1.90830811e-02 -3.12437371e-02  5.67643734e-02\n",
      " -4.85923816e-02 -6.72977203e-02 -4.06715943e-03 -5.07807256e-02\n",
      " -4.35582390e-02  1.24438926e-01 -8.76633352e-03  9.16948303e-03\n",
      "  1.37583863e-02  1.48900609e-03 -1.49587569e-02 -3.19676648e-02\n",
      " -5.89459449e-02 -2.52485294e-02  3.37672480e-02 -2.48896034e-02\n",
      "  2.36098126e-03 -3.90042120e-02  2.92164561e-02  1.90313173e-02\n",
      "  8.28544821e-03  1.90856829e-02 -3.40642695e-02  2.40101386e-02\n",
      "  1.41018450e-02  6.39312921e-02 -1.88969824e-02 -9.03693299e-03\n",
      " -7.57331216e-06 -5.99307133e-03 -1.20177294e-02 -2.00553234e-02\n",
      "  6.81881163e-03  3.40665255e-02  4.81455112e-02  1.04908003e-02\n",
      " -6.60867565e-02 -2.15513090e-02 -7.80951094e-02 -3.56620598e-02\n",
      "  9.61112162e-03 -2.90997377e-03  1.21773110e-02 -2.48873978e-02\n",
      "  1.17478480e-02  2.70754636e-02  4.45067760e-02 -4.73376395e-02\n",
      " -3.84324793e-02 -1.19837462e-02  2.74967935e-02  4.31889232e-03\n",
      " -9.58581616e-04 -8.48951153e-02 -3.93061368e-02 -4.54987277e-02\n",
      " -3.90740181e-02  2.80082883e-02 -1.58505847e-02 -2.57467299e-02\n",
      " -2.61288269e-03 -4.25861294e-02  1.61641053e-02 -6.37953351e-04\n",
      "  1.65657377e-03  3.05431952e-02  3.07562671e-02 -1.84184284e-02\n",
      " -1.65515112e-03 -1.09521160e-02  1.57526204e-01  6.28565151e-03\n",
      " -7.60023171e-03 -2.36718903e-02 -3.99494424e-02 -3.67877494e-03\n",
      " -8.53945477e-03  1.49831805e-02 -1.09288323e-01  7.81032491e-03\n",
      "  2.89289896e-02  4.37478328e-02 -1.17848214e-02 -2.94309531e-02\n",
      "  2.45065925e-02  2.09736970e-02  4.90562543e-02 -5.29908005e-02\n",
      " -2.27584222e-02 -3.32059878e-02  3.81181780e-03 -1.98575280e-02\n",
      " -3.73036124e-02  1.05555244e-02  5.93330999e-02 -1.02235460e-02\n",
      " -7.52038662e-03  5.38586703e-02 -4.37154160e-02  3.32529903e-02\n",
      " -2.45233025e-03  3.83147770e-02 -2.60985536e-02  4.87952509e-02\n",
      "  1.79225847e-02  1.84859971e-02  1.24734131e-02 -5.41341986e-02\n",
      " -2.36471291e-02  2.96053396e-02 -3.45217009e-02  1.83466488e-02\n",
      " -4.67157572e-02  9.07483799e-02 -1.68580188e-02  2.28349267e-02\n",
      "  1.79983995e-02  2.31206442e-02  3.19640424e-03  4.48604405e-04\n",
      " -1.62939917e-02 -3.59482383e-02 -4.44718530e-02 -3.69551197e-03\n",
      " -4.37432761e-02 -3.05328800e-02  3.90679978e-02  1.48311542e-02\n",
      "  8.47428532e-02 -1.81579336e-02 -2.21765238e-02 -4.05170838e-02\n",
      " -6.04691529e-02 -3.00600928e-02  1.74157799e-02  4.98699212e-02\n",
      "  4.73615524e-02 -6.24683992e-02  2.90324743e-02  3.09367175e-02\n",
      "  3.65881429e-02 -4.99564793e-02  1.03202876e-02  5.58256738e-02\n",
      "  3.47860443e-02 -6.30716832e-04  2.06445568e-02 -7.00541834e-02\n",
      " -6.91308604e-02 -2.20891314e-02  4.20024765e-02 -3.80796606e-03\n",
      " -2.47016310e-02  6.01912469e-02 -7.19663977e-02 -1.54927921e-02\n",
      " -1.23080296e-03 -3.06172870e-02 -4.20768739e-03 -2.22056087e-02\n",
      "  6.55382008e-02  4.69544570e-02 -2.01087178e-02  3.27012892e-02\n",
      "  4.27076334e-02  5.14926857e-02 -2.51986553e-02 -6.36749488e-03\n",
      "  2.38294126e-02 -1.05177776e-02 -1.40917128e-02  1.27652332e-02\n",
      " -1.12103054e-02  1.06495382e-02 -5.80083454e-02  6.32696322e-02\n",
      "  8.64123946e-02  1.57329960e-02 -1.85196421e-02  1.67242557e-03\n",
      "  1.55139096e-02 -2.50139494e-02  1.85069638e-02 -7.13248882e-03\n",
      " -2.07141531e-02 -7.87119293e-03  3.58903954e-02 -2.91239645e-02\n",
      " -3.19073050e-03  3.30804513e-02 -2.10636164e-02  6.17160319e-03\n",
      " -3.71514311e-02  4.92541075e-02  1.39203025e-02  7.03144105e-03\n",
      "  7.29482731e-02 -4.29775918e-03 -5.23236436e-03  3.72226948e-03]\n"
     ]
    }
   ],
   "source": [
    "# Omzetten van teksten naar vectoren\n",
    "vectors = embedder.encode_documents(chunks)\n",
    "\n",
    "# Een kijkje nemen naar de eerste vector = chunk 1\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd7d95",
   "metadata": {},
   "source": [
    "### **6. Vectoren in database stoppen**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc393b6c",
   "metadata": {},
   "source": [
    "<img src=\"../.github/vectors-in-database.png\" alt=\"Tekst embedding\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e6b22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_count': 13, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'cost': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"../milvus.db\")\n",
    "\n",
    "# Formatteer de vectoren als een lijst van dictionaries\n",
    "data = [ {\"text\": text, \"vector\": vector, \"id\": id} for id, (text, vector) in enumerate(zip(chunks, vectors)) ]\n",
    "\n",
    "# Vectoren toevoegen aan de blogpost collectie\n",
    "client.insert(\"blogpost\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1ef0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4459f",
   "metadata": {},
   "source": [
    "## **Vector database bevragen** *(= Retrieval)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc64ed",
   "metadata": {},
   "source": [
    "### **6. Vraag embedden**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df02fd3",
   "metadata": {},
   "source": [
    "<img src=\"../.github/vraag-embedden.png\" alt=\"RAG\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f2b5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Wat kan je me vertellen over de blogpost?\"\n",
    "\n",
    "question_vector = embedder.encode_queries([question])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb247a",
   "metadata": {},
   "source": [
    "### **7. Relevante documenten zoeken**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a044ee",
   "metadata": {},
   "source": [
    "<img src=\"../.github/relevante-docs-zoeken.png\" alt=\"RAG\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "419ba18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultaten:\n",
      "{'id': 0, 'distance': 0.43110722303390503, 'entity': {'text': 'Blogpost\\nHoe maak je AI-modellen klein en \\neffici√´nt?\\nAI-modellen worden steeds krachtiger, maar vaak ook steeds groter. Grote \\nmodellen vereisen veel rekenkracht, geheugen en energie - wat ze minder \\ngeschikt maakt voor gebruik op edge devices, maar ook realtime computervisie \\napplicaties zoals de Howest Virtual Mirror. Gelukkig zijn er diverse technieken \\nom AI-modellen te verkleinen zonder de accuraatheid ervan te verlagen. In \\ndeze blogpost bespreken we de belangrijkste optimalisatiestrategie√´n: \\nquanti'}}\n",
      "{'id': 12, 'distance': 0.3301771879196167, 'entity': {'text': 'putervisie en taalmodellen maken ze het \\nverschil.\\nHet vergt wel enige tijd om mee te experimenteren en het verlies in \\naccuraatheid te beoordelen en/of te compenseren. Deze extra ontwikkelingstijd \\nkan afhankelijk van de schaal van het project al dan niet de moeite waard zijn.\\nBlogpost\\n5\\n'}}\n",
      "{'id': 1, 'distance': 0.3106725811958313, 'entity': {'text': 'satie, distillatie, pruning en meer. We bekijken ook welke tools je kunt \\ngebruiken, op welke platformen ze draaien, en hoe groot de impact kan zijn.\\n1. Quantisatie\\nInleiding\\nBinnenin een AI model zitten er miljoenen tot miljarden kommagetallen - ook \\nwel ‚ÄúgewichtenÀÆ en ‚ÄúactivatiesÀÆ genoemd. Elk getal neemt typisch 32 bits \\n(nullen en enen) geheugen in beslag.\\nVoor een computer zijn kommagetallen eigenlijk zeer lastig om mee te rekenen. \\n√â√©n zo ºn berekening duurt uiteraard slechts enkele nanoseconden (of mi'}}\n",
      "{'id': 10, 'distance': 0.29345083236694336, 'entity': {'text': 'Qwen-7B\\ue082. Een ouder succesverhaal van distillatie is \\nTinyBERT. Die is ruim 7 keer kleiner en 9 keer sneller dan het oorspronkelijke \\nBERT terwijl het slecht een daling van ¬±3% heeft in nauwkeurigheid \\n(https://arxiv.org/pdf/1909.10351\\ue082.\\nSamenvatting\\nBlogpost\\n4\\nOptimalisatietechnieken kunnen een sterk voordeel bieden op vlak van \\nsnelheid, energieconsumptie, kostprijs, hardware beperkingen en speelt een \\ngrote rol in computervisie en taalmodellen. Het vergt wel enige tijd om mee te \\nexperimenteren en het ve'}}\n",
      "{'id': 7, 'distance': 0.2897223234176636, 'entity': {'text': 'rekeningen die moeten gemaakt worden waardoor het \\nmodel sneller zal zijn.\\nEr bestaan twee soorten pruning:\\nNiet-gestructureerde pruning: verwijderen van individuele gewichten of \\nverbindingen.\\nGestructureerde pruning: verwijderen van hele filters, neuronen of lagen.\\nBlogpost\\n3\\nOok hier kan je het model hertrainen of finetunen na het prunen om het kleine \\nverlies in accuraatheid te compenseren.\\nFrameworks\\nEr bestaan Python-libraries die functies bevatten om jouw model te prunen:\\nGebruik de ‚Äútorch.nn.utils.p'}}\n",
      "{'id': 8, 'distance': 0.25696465373039246, 'entity': {'text': 'runeÀÆ library voor PyTorch modellen.\\nGebruik de ‚Äútensorflow_model_optimization.sparsity.kerasÀÆ library voor \\nTensorFlow modellen.\\nOok Hugging Face ºs Optimum library beschikt over pruning mogelijkheden \\nvoor Intel-systemen.\\n3. Kennisdistillatie\\nKennisdistillatie is een techniek waarbij een klein model wordt getraind om de \\noutput van een groot, krachtig model te imiteren. Men beschrijft dit vaak als \\neen student-leerkracht relatie.\\nHet leerkracht-model werd getraind door te leren uit grote hoeveelheden data.'}}\n",
      "{'id': 9, 'distance': 0.256732702255249, 'entity': {'text': ' \\nHet student-model daarentegen, wordt enkel getraind wordt op de output van \\neen (reeds getraind) leerkracht-model en komt eigenlijk nooit in aanraking met \\nde oorspronkelijke data.\\nIn de praktijk blijkt dat student-modellen vaak bijna dezelfde nauwkeurigheid \\nkunnen bereiken als het leerkracht-model terwijl ze veel kleiner en sneller zijn. \\nVoorbeeld: Het Chinese DeepSeek ontwikkelt gedistilleerde taalmodellen aan \\nzoals DeepSeek-R1\\ue088Distill-Qwen-7B (https://huggingface.co/deepseek-\\nai/DeepSeek-R1\\ue088Distill-'}}\n",
      "{'id': 11, 'distance': 0.25431740283966064, 'entity': {'text': 'rlies in accuraatheid te beoordelen en/of te \\ncompenseren. Deze extra ontwikkelingstijd kan afhankelijk van de schaal van \\nhet project wel of niet de moeite waard zijn. Of de implementatie van √©√©n of \\nmeerdere van deze technieken interessant is, moet dus voor elk scenario \\nindividueel beoordeeld worden.\\nSamenvatting\\nOptimalisatietechnieken zoals quantisatie, pruning en distillatie kunnen heel \\nvoordelig zijn op vlak van snelheid, energieverbruik, kostprijs en hardware-\\neisen. Zeker in toepassingen zoals com'}}\n",
      "{'id': 2, 'distance': 0.24596591293811798, 'entity': {'text': 'nder), \\nmaar door de enorme hoeveelheid ervan loopt deze vertraging zo hoog op dat \\nhet uiteindelijke model er seconden tot minuten over doet om data te \\nverwerken.\\nVoorbeeld: elk sub-woord dat door GPT\\ue0884 genereert wordt moet door 1 tot 2 \\nbiljoen parameters verwerkt worden. Beeld je maar in hoeveel berekeningen \\nnodig zijn om een volledige tekst te genereren. Dit is de reden dat er voor AI \\nzo ºn grote nood is aan krachtige GPU ºs.\\nBestaand model quantiseren\\nPost-training quantization \\ue081PTQ\\ue082 is het proces waa'}}\n",
      "{'id': 6, 'distance': 0.22890782356262207, 'entity': {'text': 'y voor PyTorch modellen. Dit is een \\nonderdeel van de PyTorch Architecture Optimization library.\\nGebruik ‚Äúonnxruntime.quantizationÀÆ library voor modellen die ge√´xporteerd \\nzijn als een gestandaardiseerd ONNX formaat.\\nOok Hugging Face ºs Optimum library beschikt over quantisatie \\nmogelijkheden voor ONNX modellen en Intel-systemen.\\n2. Pruning\\nPruning verwijdert elementen uit het model die weinig bijdragen aan het \\nuiteindelijke resultaat ervan. Het verminderen van overbodige parameters \\nverkleint het aantal be'}}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"../milvus.db\")\n",
    "\n",
    "results = client.search(\n",
    "    collection_name=\"blogpost\",\n",
    "    data=[question_vector],\n",
    "    output_fields=[\"text\"]\n",
    ")\n",
    "\n",
    "print(\"Resultaten:\")\n",
    "for result in results[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc56f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831ff41",
   "metadata": {},
   "source": [
    "## **Antwoord formuleren** *(= Generation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994945ce",
   "metadata": {},
   "source": [
    "### **8. Taalmodel bevragen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deze blogpost behandelt verschillende technieken om AI-modellen klein en effici√´nt te maken zonder hun accuratesse te verliezen. De belangrijkste optimalisatiestrategie√´n die worden besproken zijn quantisatie, pruning en distillatie. Quantisatie verwijdert niet-binaire getallen uit het model, pruning verwijdert onnodige elementen uit het model en distillatie traineert een klein model om de output van een groot model te imiteren.\n",
      "\n",
      "De blogpost geeft ook voorbeelden van hoe deze technieken worden toegepast in praktijk, zoals TinyBERT, die 7 keer kleiner en 9 keer sneller is dan het oorspronkelijke BERT-model terwijl het slechts een kleine daling van ¬±3% heeft in nauwkeurigheid.\n",
      "\n",
      "Verder wordt er ook gesproken over frameworks en libraries die kunnen worden gebruikt om modellen te optimaliseren, zoals PyTorch, TensorFlow en Hugging Face's Optimum library.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Je bent een professionele assistent. Gebruik onderstaande context om de vraag te beantwoorden.\n",
    "Als het antwoord niet in de context staat, zeg dan dat je het niet weet.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Vraag:\n",
    "{question}\n",
    "\n",
    "### Antwoord:\n",
    "\"\"\"\n",
    "\n",
    "def vraag_ollama_rag(context, question, model=\"llama3\"):\n",
    "    response = chat(model=model, messages=[{\"role\": \"user\", \"content\": prompt_template.format(context=context, question=question)}])\n",
    "    return response.message.content.strip()\n",
    "\n",
    "# Chunks van gevonden documenten terug aan elkaar plakken om context te vormen\n",
    "context = \"\\n\\n\".join([result.entity.text.strip() for result in results[0]])\n",
    "\n",
    "# Vraag stellen aan Ollama met de context en de vraag\n",
    "answer = vraag_ollama_rag(context, question)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

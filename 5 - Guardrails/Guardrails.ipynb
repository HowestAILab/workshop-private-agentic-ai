{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42600a3",
   "metadata": {},
   "source": [
    "# **GUARDRAILS**\n",
    "Als we agentic AI systemen in productie willen draaien moeten we niet alleen verzekeren dat ze correcte informatie geven maar ook dat ze niet antwoorden op vragen die niet relevant zijn aan hun doel.  \n",
    "\n",
    "Een bot die ingezet wordt voor verzekeringsadvies moet geen antwoorden kunnen geven over recepten bijvoorbeeld.  \n",
    "Hiervoor kunnen we guardrail systemen gebruiken. \n",
    "\n",
    "In deze demo bouwen we verder op de RAG notebook en gaan we een extra laag toevoegen waarbij we via de open source guardrails-ai library het gegenereerde antwoord gaan valideren vooraleer we het terug aan de gebruiker tonen.\n",
    "\n",
    "Je kan alle mogelijke validators binnen de guardrails-ai library [hier](https://hub.guardrailsai.com/) terugvinden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32984f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b915dec",
   "metadata": {},
   "source": [
    "## **Voorbereiding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b98210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymilvus[model] pypdf ollama --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0827b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786e678",
   "metadata": {},
   "source": [
    "## **Embedder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16eedb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elke vector zal uit 768 kommagetallen bestaan.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "\n",
    "# Laadt een standaard embedder model\n",
    "embedder = model.DefaultEmbeddingFunction()\n",
    "\n",
    "print(f\"Elke vector zal uit {embedder.dim} kommagetallen bestaan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8723d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ed4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "vectordb = MilvusClient(\"../milvus.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ada22",
   "metadata": {},
   "source": [
    "### **2. Maak een collectie aan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce0c8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beschikbare collecties: LangChainCollection, blogpost\n"
     ]
    }
   ],
   "source": [
    "collections = vectordb.list_collections()\n",
    "\n",
    "if \"blogpost\" not in collections:\n",
    "  # Aanmaken van nieuwe collectie\n",
    "  vectordb.create_collection(\n",
    "    collection_name=\"blogpost\",\n",
    "    dimension=embedder.dim\n",
    "  )\n",
    "\n",
    "# Lijst alle collecties op ter controle\n",
    "collections = vectordb.list_collections()\n",
    "print(f\"Beschikbare collecties: {', '.join(collections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb73419",
   "metadata": {},
   "source": [
    "### **3. Uitlezen van PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54374fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def lees_pdf(path):\n",
    "    # Open de PDF\n",
    "    pdf = PdfReader(path)\n",
    "    text = \"\"\n",
    "    # Overloop elke pagina\n",
    "    for page in pdf.pages:\n",
    "        # Lees de paginatekst uit\n",
    "        page_text = page.extract_text()\n",
    "        # Voeg de paginatekst toe aan de totale tekst\n",
    "        text += page_text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ec28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blogpost\n",
      "Hoe maak je AI-modellen klein en \n",
      "efficiënt?\n",
      "AI-modellen worden steeds krachtiger, maar vaak ook steeds groter. Grote \n",
      "modellen vereisen veel rekenkracht, geheugen en energie - wat ze minder \n",
      "geschikt maakt voor gebruik op edge devices, maar ook realtime computervisie \n",
      "applicaties zoals de Howest Virtual Mirror. Gelukkig zijn er diverse technieken \n",
      "om AI-modellen te verkleinen zonder de accuraatheid ervan te verlagen. In \n",
      "deze blogpost bespreken we de belangrijkste optimalisatiestrategieën: \n",
      "quantisatie, distillatie, pruning en meer. We bekijken ook welke tools je kunt \n",
      "gebruiken, op welke platformen ze draaien, en hoe groot de impact kan zijn.\n",
      "1. Quantisatie\n",
      "Inleiding\n",
      "Binnenin een AI model zitten er miljoenen tot miljarden kommagetallen - ook \n",
      "wel “gewichtenˮ en “activatiesˮ genoemd. Elk getal neemt typisch 32 bits \n",
      "(nullen en enen) geheugen in beslag.\n",
      "Voor een computer zijn kommagetallen eigenlijk zeer lastig om mee te rekenen. \n",
      "Één zoʼn berekening duurt uiteraard slechts enkele nanoseconden (of minder), \n",
      "maar door de enorme hoeveelheid ervan loopt deze vertraging zo hoog op dat \n",
      "het uiteindelijke model er seconden tot minuten over doet om data te \n",
      "verwerken.\n",
      "Voorbeeld: elk sub-woord dat door GPT4 genereert wordt moet door 1 tot 2 \n",
      "biljoen parameters verwerkt worden. Beeld je maar in hoeveel berekeningen \n",
      "nodig zijn om een volledige tekst te genereren. Dit is de reden dat er voor AI \n",
      "zoʼn grote nood is aan krachtige GPUʼs.\n",
      "Bestaand model quantiseren\n",
      "Post-training quantization PTQ is het proces waarbij de getallen in een reeds \n",
      "getraind model worden omgezet van 32-bit floating-point FP32 naar een \n",
      "lagere precisie, zoals 16-bit FP16 of zelfs 8-bit integers INT8. Concreet heb \n",
      "Blogpost\n",
      "1\n",
      "je dan minder cijfers na de komma, of zelfs helemaal geen kommagetallen \n",
      "meer.\n",
      "Impact:\n",
      "Tot 4x verkleining van modelgrootte (van FP32 naar INT8.\n",
      "2x tot 4x snelheidsverbetering.\n",
      "Vaak minimaal verlies in nauwkeurigheid 5%.\n",
      "Wat men vaak doet is het gequantiseerde model nog eens kort hertrainen of \n",
      "finetunen met gequantiseerde data. Dikwijls verhoogt dit de accuraatheid \n",
      "opnieuw naar het oorspronkelijke niveau van het niet-gequantiseerde model.\n",
      "Gequantiseerd trainen\n",
      "Een tweede mogelijkheid is Quantized Aware Training QAT. Hierbij traint men \n",
      "het model met reeds afgeronde getallen om het quantisatie-effect te simuleren. \n",
      "Typisch levert dit nog betere resultaten op dan PTQ, maar je moet het op \n",
      "voorhand in rekening brengen of je model volledig hertrainen.\n",
      "Voorbeelden: op Ollama kan je van sommige taalmodellen - zoals de gemma3 \n",
      "familie - ook QAT-varianten terugvinden die tot 3 keer sneller zijn \n",
      "(https://ollama.com/library/gemma34b-it-qat). Ook van computervisie \n",
      "modellen zoals YOLO bestaan PTQ-varianten zoals YOLOv8Detection-\n",
      "Quantized (https://huggingface.co/qualcomm/YOLOv8Detection-Quantized).\n",
      "Frameworks\n",
      "Er bestaan verschillende Python-libraries die functies bevatten om jouw model \n",
      "te quantiseren:\n",
      "Gebruik de “tf.lite.Optimizeˮ library voor TensorFlow modellen.\n",
      "Blogpost\n",
      "2\n",
      "Gebruik de “torch.ao.quantizationˮ library voor PyTorch modellen. Dit is een \n",
      "onderdeel van de PyTorch Architecture Optimization library.\n",
      "Gebruik “onnxruntime.quantizationˮ library voor modellen die geëxporteerd \n",
      "zijn als een gestandaardiseerd ONNX formaat.\n",
      "Ook Hugging Faceʼs Optimum library beschikt over quantisatie \n",
      "mogelijkheden voor ONNX modellen en Intel-systemen.\n",
      "2. Pruning\n",
      "Pruning verwijdert elementen uit het model die weinig bijdragen aan het \n",
      "uiteindelijke resultaat ervan. Het verminderen van overbodige parameters \n",
      "verkleint het aantal berekeningen die moeten gemaakt worden waardoor het \n",
      "model sneller zal zijn.\n",
      "Er bestaan twee soorten pruning:\n",
      "Niet-gestructureerde pruning: verwijderen van individuele gewichten of \n",
      "verbindingen.\n",
      "Gestructureerde pruning: verwijderen van hele filters, neuronen of lagen.\n",
      "Blogpost\n",
      "3\n",
      "Ook hier kan je het model hertrainen of finetunen na het prunen om het kleine \n",
      "verlies in accuraatheid te compenseren.\n",
      "Frameworks\n",
      "Er bestaan Python-libraries die functies bevatten om jouw model te prunen:\n",
      "Gebruik de “torch.nn.utils.pruneˮ library voor PyTorch modellen.\n",
      "Gebruik de “tensorflow_model_optimization.sparsity.kerasˮ library voor \n",
      "TensorFlow modellen.\n",
      "Ook Hugging Faceʼs Optimum library beschikt over pruning mogelijkheden \n",
      "voor Intel-systemen.\n",
      "3. Kennisdistillatie\n",
      "Kennisdistillatie is een techniek waarbij een klein model wordt getraind om de \n",
      "output van een groot, krachtig model te imiteren. Men beschrijft dit vaak als \n",
      "een student-leerkracht relatie.\n",
      "Het leerkracht-model werd getraind door te leren uit grote hoeveelheden data. \n",
      "Het student-model daarentegen, wordt enkel getraind wordt op de output van \n",
      "een (reeds getraind) leerkracht-model en komt eigenlijk nooit in aanraking met \n",
      "de oorspronkelijke data.\n",
      "In de praktijk blijkt dat student-modellen vaak bijna dezelfde nauwkeurigheid \n",
      "kunnen bereiken als het leerkracht-model terwijl ze veel kleiner en sneller zijn. \n",
      "Voorbeeld: Het Chinese DeepSeek ontwikkelt gedistilleerde taalmodellen aan \n",
      "zoals DeepSeek-R1Distill-Qwen-7B (https://huggingface.co/deepseek-\n",
      "ai/DeepSeek-R1Distill-Qwen-7B. Een ouder succesverhaal van distillatie is \n",
      "TinyBERT. Die is ruim 7 keer kleiner en 9 keer sneller dan het oorspronkelijke \n",
      "BERT terwijl het slecht een daling van ±3% heeft in nauwkeurigheid \n",
      "(https://arxiv.org/pdf/1909.10351.\n",
      "Samenvatting\n",
      "Blogpost\n",
      "4\n",
      "Optimalisatietechnieken kunnen een sterk voordeel bieden op vlak van \n",
      "snelheid, energieconsumptie, kostprijs, hardware beperkingen en speelt een \n",
      "grote rol in computervisie en taalmodellen. Het vergt wel enige tijd om mee te \n",
      "experimenteren en het verlies in accuraatheid te beoordelen en/of te \n",
      "compenseren. Deze extra ontwikkelingstijd kan afhankelijk van de schaal van \n",
      "het project wel of niet de moeite waard zijn. Of de implementatie van één of \n",
      "meerdere van deze technieken interessant is, moet dus voor elk scenario \n",
      "individueel beoordeeld worden.\n",
      "Samenvatting\n",
      "Optimalisatietechnieken zoals quantisatie, pruning en distillatie kunnen heel \n",
      "voordelig zijn op vlak van snelheid, energieverbruik, kostprijs en hardware-\n",
      "eisen. Zeker in toepassingen zoals computervisie en taalmodellen maken ze het \n",
      "verschil.\n",
      "Het vergt wel enige tijd om mee te experimenteren en het verlies in \n",
      "accuraatheid te beoordelen en/of te compenseren. Deze extra ontwikkelingstijd \n",
      "kan afhankelijk van de schaal van het project al dan niet de moeite waard zijn.\n",
      "Blogpost\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = lees_pdf(\"Blogpost.pdf\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b26fdc",
   "metadata": {},
   "source": [
    "### **4. Tekst opsplitsen in chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750ee014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De tekst van 6434 karakters is opgedeeld in 17 stukken van 512 karakters met een overlap van 128 karakters.\n"
     ]
    }
   ],
   "source": [
    "def verdeel_in_chunks(text):\n",
    "    # Kap de tekst in stukken van 512 karakters met een overlap van 128 karakters\n",
    "    return [text[i:i+512] for i in range(0, len(text), 512-128)]\n",
    "\n",
    "chunks = verdeel_in_chunks(text)\n",
    "\n",
    "print(f\"De tekst van {len(text)} karakters is opgedeeld in {len(chunks)} stukken van 512 karakters met een overlap van 128 karakters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8df0f5",
   "metadata": {},
   "source": [
    "### **5. Chunks omzetten naar vectoren (embedding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed09b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.29018397e-02  3.39037056e-02  1.38407705e-02 -2.37033750e-02\n",
      "  1.41432738e-02  3.95084573e-03  1.88760994e-02 -8.68979462e-03\n",
      "  1.15502403e-02 -5.03735965e-02  2.82360528e-02  1.72524620e-02\n",
      " -4.01088364e-02 -9.24565788e-02  4.08351003e-03  8.70586708e-03\n",
      " -4.49316399e-02 -2.97982155e-02  9.14868732e-03 -3.51780520e-02\n",
      " -2.84741317e-02  7.10664068e-03  6.14569991e-03 -4.83656797e-02\n",
      " -1.91956371e-02  2.58579654e-02 -2.50019176e-03  6.60994206e-03\n",
      " -2.69456916e-02 -6.56962520e-03 -6.13001482e-02 -1.31405158e-02\n",
      " -1.11234524e-03 -1.92446541e-02 -5.01197160e-02 -5.89044375e-02\n",
      " -4.28711448e-03  1.35903676e-02 -1.09149342e-02  4.75778749e-02\n",
      " -1.04830449e-02  1.61411409e-02  5.04271557e-03  9.73946011e-02\n",
      " -1.69800678e-02  4.72020984e-02  3.78694586e-02 -1.64446858e-02\n",
      " -3.84101321e-02 -4.90670064e-02  5.57477220e-02 -2.05239546e-02\n",
      " -1.50153661e-02  2.02639093e-02 -3.07706504e-02  1.58992888e-02\n",
      "  2.00894465e-02 -5.43083171e-02  1.18508442e-02 -2.68718704e-02\n",
      "  1.21450267e-02 -2.39214409e-02  5.86705900e-02 -3.61095760e-02\n",
      " -4.11704393e-02 -3.05174746e-02  3.14643562e-02 -5.15372869e-02\n",
      "  2.54327067e-02 -8.62432474e-03 -2.84373588e-02 -4.64107920e-02\n",
      " -8.60515502e-03  6.41534523e-03  1.77646805e-02 -2.75246555e-02\n",
      "  4.05787941e-02  6.93191224e-02 -3.40865088e-02  9.66285353e-03\n",
      " -1.27230790e-02 -5.14471577e-04 -1.10420833e-02 -1.30841580e-02\n",
      " -7.23763181e-03  4.86812384e-02  1.81783370e-02  7.78857813e-03\n",
      " -6.80205300e-03  1.52834512e-02 -2.06837736e-02  1.52569340e-03\n",
      "  7.51989372e-03  3.27629697e-02  1.93539641e-02  8.12509284e-04\n",
      "  4.93492356e-04 -2.83715774e-02  2.21216301e-02 -1.22368625e-02\n",
      "  4.53555150e-02  1.50839244e-02 -4.37312473e-02  7.89725819e-02\n",
      " -6.86880269e-03  2.99914342e-02 -5.21590935e-02 -2.67936480e-03\n",
      " -3.26215990e-02  3.24733189e-02  7.62745810e-03 -1.53997838e-03\n",
      " -3.05134963e-02  1.30945189e-02 -6.00476900e-02  3.37007080e-02\n",
      " -3.51591675e-02 -6.14176502e-02  2.00682581e-02 -1.25138245e-02\n",
      "  1.15944293e-03 -8.69020606e-02  1.35035303e-01 -4.77658912e-02\n",
      "  6.81348792e-02  5.69250374e-02  1.98505585e-02 -7.60722262e-03\n",
      "  3.63328308e-02  1.21665211e-02 -6.67122343e-02  4.37948348e-02\n",
      "  5.58630633e-02  4.36157114e-02 -1.56763138e-02  5.46735590e-03\n",
      "  1.05680826e-02  1.12618790e-02 -1.25880984e-02  6.15648692e-02\n",
      " -4.00706519e-02  9.54690200e-03 -1.05000970e-02  2.54885264e-02\n",
      "  7.73917935e-03 -6.76430987e-03 -1.45775680e-02  1.14924083e-02\n",
      " -3.32918839e-02  7.25952227e-02  1.55882052e-03  3.15254819e-02\n",
      " -9.05846258e-03  3.28092457e-02 -2.47797608e-02  2.11368854e-02\n",
      "  4.17592061e-02  3.79725679e-02  4.03129617e-03  2.75199676e-02\n",
      " -3.64364591e-02 -3.67049691e-02 -5.00097429e-03  6.43647737e-03\n",
      "  4.01844290e-02  1.97040534e-02  1.29161155e-02 -4.40828720e-02\n",
      " -2.47980348e-02 -1.01318725e-02 -1.97954234e-02 -8.04329508e-03\n",
      " -1.37253653e-02  3.52287083e-02  4.40125992e-02  1.96309773e-02\n",
      " -2.21114602e-02  2.74205803e-02 -3.85074843e-02  2.47454651e-02\n",
      " -1.53780651e-02 -6.54478569e-02 -4.10286483e-04 -4.17411555e-02\n",
      " -1.08633394e-01 -2.34191794e-02  1.19084104e-02  5.77869606e-02\n",
      "  3.01943383e-02  1.14006947e-02 -1.21524627e-02 -1.65398443e-02\n",
      "  4.46837468e-02 -9.82887756e-02 -5.10967271e-02 -1.47878490e-03\n",
      "  7.57362598e-02  4.69748042e-02  1.21585478e-02 -1.21653979e-02\n",
      " -3.57738625e-02  3.29982519e-02 -2.47575667e-02 -4.74902478e-03\n",
      " -1.38650750e-02  3.54024461e-02 -1.02741380e-02 -1.83970390e-02\n",
      "  3.50892988e-02  2.27800753e-02  4.85937270e-02  4.19493760e-02\n",
      "  5.58204782e-03  2.01270565e-02  8.64438015e-02  4.27830522e-02\n",
      " -1.15271825e-02  5.30562089e-02 -4.99152006e-02  1.07081013e-02\n",
      "  1.08904745e-02  4.48052311e-02 -2.48611720e-02 -2.67264195e-02\n",
      " -3.80678703e-03  1.71548398e-03 -2.92502700e-02  6.40728445e-02\n",
      " -2.41556937e-02 -3.11177884e-04  1.61926448e-02  2.48861372e-02\n",
      "  4.19413723e-02  6.29891057e-02 -1.10093441e-02 -2.41922991e-02\n",
      "  7.26950772e-02 -1.76693471e-03 -3.97130998e-02 -2.19562446e-02\n",
      " -5.26816214e-02  7.77820383e-03  2.81375160e-02 -3.78988594e-02\n",
      "  5.55995866e-02  3.70276364e-03 -2.19400739e-02  9.07304303e-04\n",
      "  2.45818895e-02 -6.56266772e-02 -6.62461857e-02 -5.41731520e-02\n",
      "  1.91269850e-03  1.48637377e-02 -3.73244228e-02  1.26515863e-03\n",
      "  1.25810126e-02 -4.28534817e-02 -3.76794547e-02 -4.60391561e-02\n",
      " -9.69605009e-03 -1.13203993e-02 -3.89260357e-02  3.90191477e-02\n",
      " -4.40297619e-03  3.69700165e-02  2.31314405e-02  8.04737922e-03\n",
      " -2.76821069e-02  3.86876640e-02  1.25967881e-02 -4.11340576e-02\n",
      " -3.67877122e-02 -5.35488201e-02 -3.00374346e-02  1.45131152e-02\n",
      " -3.95472419e-03  6.24235763e-03 -4.83149490e-02 -4.24798631e-02\n",
      " -5.16404957e-02  1.63635523e-02  2.71407838e-03 -1.65586343e-02\n",
      "  4.04042677e-02  1.35038332e-03 -2.55763021e-02 -7.62204117e-02\n",
      "  1.60973095e-02 -4.45756308e-02 -5.77564455e-02  9.59892595e-03\n",
      " -5.88999536e-02 -2.64320195e-02 -1.58739145e-02  3.83749359e-02\n",
      "  6.19639489e-02  1.38845983e-02  3.32050251e-02 -5.84684713e-02\n",
      "  5.86367748e-02  2.68323391e-02 -1.39255792e-04 -6.82403229e-02\n",
      "  9.68132195e-03  4.86460382e-02 -3.41996337e-02 -4.33379283e-02\n",
      " -2.36026014e-02  1.86529355e-02 -2.01815391e-02 -2.61617870e-02\n",
      "  2.63423422e-02 -3.78661405e-03  2.38670811e-02  1.80422416e-02\n",
      "  2.43591072e-02 -3.15434479e-02 -2.34681553e-02  4.10473149e-02\n",
      " -4.64214771e-02 -3.16246082e-02 -4.60287435e-02  2.41655795e-02\n",
      " -7.02496929e-02  5.75260597e-03  3.10377126e-03  1.86515834e-03\n",
      " -1.13490785e-02  4.51385085e-02 -2.75052050e-02  3.81217402e-02\n",
      " -3.77473263e-02 -3.66991344e-02  1.94617191e-03  1.01533845e-02\n",
      " -2.88501737e-02  2.53184682e-02  5.28403477e-02  5.48570795e-02\n",
      " -1.04051184e-02  8.35227833e-03 -4.05000126e-02 -3.95726695e-02\n",
      "  4.37915236e-02 -2.58229248e-02 -1.95882881e-03 -1.83181555e-02\n",
      " -2.56138640e-03 -2.53897127e-02 -1.72105168e-02 -8.54047770e-03\n",
      " -4.00735579e-02  4.68037381e-02 -2.34592568e-02 -1.05757919e-02\n",
      " -7.49958032e-03  9.38533688e-03  5.57300350e-03  5.91945498e-02\n",
      " -3.77700767e-02  6.20723192e-03 -2.32309286e-02  3.66549960e-02\n",
      " -1.23853475e-02  2.65349025e-03 -4.46967565e-02 -1.44165243e-02\n",
      "  3.64262922e-02  7.57420319e-03 -1.98008074e-02  1.14977852e-03\n",
      "  2.31119857e-02 -6.65778013e-02 -5.98554028e-02 -9.08710652e-03\n",
      "  1.10994123e-02 -9.71615762e-02 -5.51877171e-02 -2.02556562e-02\n",
      "  3.58096804e-02  3.18187996e-02  1.27822766e-02  1.94794535e-02\n",
      " -4.82594395e-02  3.16822664e-02 -1.32055573e-02 -4.06359127e-02\n",
      "  6.86017598e-04  7.97978804e-03 -2.64326628e-02  1.21449789e-02\n",
      " -3.33198039e-02 -5.98141676e-03 -7.00149641e-03  1.40364071e-02\n",
      "  1.05124233e-03 -3.78792955e-02  4.33167211e-02  5.35643284e-02\n",
      "  4.45757675e-02  1.78363158e-02 -6.43025089e-02  3.28013031e-02\n",
      "  6.20182767e-03  6.77320361e-02  9.11664640e-03 -2.18719166e-02\n",
      " -1.52722451e-02 -1.24787344e-02 -1.25167368e-02  5.18947463e-02\n",
      " -5.53068999e-02  9.60374656e-03 -2.46697026e-03  6.41778004e-03\n",
      "  3.62028011e-02 -4.56352521e-02  2.57600068e-02 -2.75610399e-02\n",
      "  8.67469527e-02  1.01250042e-02  1.90956104e-02  2.97375094e-02\n",
      "  1.17174336e-02  3.27926836e-02  1.93980950e-02 -4.27530580e-02\n",
      "  4.19917973e-03 -4.09885493e-02  6.39165899e-03  1.97633775e-02\n",
      " -1.51605290e-02 -4.14404631e-02 -3.02595608e-02  3.94182831e-02\n",
      "  9.79193409e-03 -3.08853587e-02  4.45985993e-03  6.02621708e-04\n",
      "  1.89497477e-02  1.21336624e-02 -4.21404678e-02  1.69857135e-02\n",
      "  7.96656935e-02  1.87562792e-02 -5.21486572e-02 -1.58418525e-02\n",
      " -9.74471182e-03  2.95155776e-02 -5.56861654e-02  1.74495435e-02\n",
      " -7.02930017e-02 -6.29441203e-02  1.23776773e-02 -7.88001642e-02\n",
      " -2.12429289e-02  4.48197449e-02  4.46453050e-02  2.56537398e-02\n",
      " -7.60093255e-02  3.99727746e-02 -5.08371787e-02  5.21552974e-02\n",
      " -2.93499406e-02 -3.92394404e-02 -2.28575742e-02  7.85528940e-03\n",
      "  2.06884599e-02 -2.22027113e-02 -3.49985884e-02  2.00427241e-02\n",
      "  2.24220496e-02 -2.52052537e-02 -3.55581930e-03  1.20038393e-02\n",
      "  1.68657203e-02  3.18015654e-02  7.01911974e-02 -2.88399430e-03\n",
      "  3.42543497e-02 -2.77589823e-02 -2.71129956e-02  1.79851828e-02\n",
      " -1.48446037e-02  2.91109891e-02  5.03921723e-03 -1.34103680e-02\n",
      "  9.38122324e-02  5.77374830e-02  1.44390009e-02 -2.99785669e-02\n",
      "  1.60231615e-02 -2.91537258e-03 -1.03215370e-02  6.58704927e-03\n",
      "  2.77996662e-03 -5.23082024e-02 -1.62719500e-02  3.78938257e-02\n",
      "  9.88574292e-02  1.35627597e-02  4.05806237e-02  3.71762628e-03\n",
      "  3.27437085e-02 -4.65115256e-02 -1.64752534e-02  7.08357477e-02\n",
      " -2.02308636e-02 -8.19607098e-03  3.89378589e-02 -9.17030469e-04\n",
      "  6.46735103e-02  2.47894542e-02 -3.49180297e-02 -7.35774498e-02\n",
      "  3.54211826e-02 -7.97761273e-04 -6.07050917e-02  3.12786474e-02\n",
      "  6.41713066e-02  1.35825684e-03 -3.92977693e-03  2.34592040e-03\n",
      " -1.80077311e-03 -1.25613957e-02 -3.07518668e-02 -2.02449219e-02\n",
      "  4.66298869e-02 -3.31203167e-02 -4.35009539e-03 -4.43886646e-02\n",
      "  3.62026785e-02  5.10123639e-04  3.83664057e-02  2.31143211e-02\n",
      "  3.74994176e-02  6.68608936e-04 -7.58827870e-03  3.46811406e-02\n",
      " -3.86117961e-02 -1.08467948e-02  8.33794914e-02 -3.22930169e-02\n",
      "  2.29362493e-02 -5.02495355e-02 -1.91227995e-02  2.89755138e-02\n",
      " -4.21529768e-02 -2.80794464e-02  1.99666450e-02  3.35532220e-02\n",
      "  1.48460150e-02 -3.93938897e-02  2.58254169e-02  3.03234477e-02\n",
      "  1.69936621e-02 -3.32680905e-02  5.87104757e-05  3.90060542e-03\n",
      "  2.59776522e-02 -1.25538342e-02 -1.03383805e-01  8.38827587e-03\n",
      "  1.52882256e-03  1.90830811e-02 -3.12437371e-02  5.67643734e-02\n",
      " -4.85923816e-02 -6.72977203e-02 -4.06715943e-03 -5.07807256e-02\n",
      " -4.35582390e-02  1.24438926e-01 -8.76633352e-03  9.16948303e-03\n",
      "  1.37583863e-02  1.48900609e-03 -1.49587569e-02 -3.19676648e-02\n",
      " -5.89459449e-02 -2.52485294e-02  3.37672480e-02 -2.48896034e-02\n",
      "  2.36098126e-03 -3.90042120e-02  2.92164561e-02  1.90313173e-02\n",
      "  8.28544821e-03  1.90856829e-02 -3.40642695e-02  2.40101386e-02\n",
      "  1.41018450e-02  6.39312921e-02 -1.88969824e-02 -9.03693299e-03\n",
      " -7.57331216e-06 -5.99307133e-03 -1.20177294e-02 -2.00553234e-02\n",
      "  6.81881163e-03  3.40665255e-02  4.81455112e-02  1.04908003e-02\n",
      " -6.60867565e-02 -2.15513090e-02 -7.80951094e-02 -3.56620598e-02\n",
      "  9.61112162e-03 -2.90997377e-03  1.21773110e-02 -2.48873978e-02\n",
      "  1.17478480e-02  2.70754636e-02  4.45067760e-02 -4.73376395e-02\n",
      " -3.84324793e-02 -1.19837462e-02  2.74967935e-02  4.31889232e-03\n",
      " -9.58581616e-04 -8.48951153e-02 -3.93061368e-02 -4.54987277e-02\n",
      " -3.90740181e-02  2.80082883e-02 -1.58505847e-02 -2.57467299e-02\n",
      " -2.61288269e-03 -4.25861294e-02  1.61641053e-02 -6.37953351e-04\n",
      "  1.65657377e-03  3.05431952e-02  3.07562671e-02 -1.84184284e-02\n",
      " -1.65515112e-03 -1.09521160e-02  1.57526204e-01  6.28565151e-03\n",
      " -7.60023171e-03 -2.36718903e-02 -3.99494424e-02 -3.67877494e-03\n",
      " -8.53945477e-03  1.49831805e-02 -1.09288323e-01  7.81032491e-03\n",
      "  2.89289896e-02  4.37478328e-02 -1.17848214e-02 -2.94309531e-02\n",
      "  2.45065925e-02  2.09736970e-02  4.90562543e-02 -5.29908005e-02\n",
      " -2.27584222e-02 -3.32059878e-02  3.81181780e-03 -1.98575280e-02\n",
      " -3.73036124e-02  1.05555244e-02  5.93330999e-02 -1.02235460e-02\n",
      " -7.52038662e-03  5.38586703e-02 -4.37154160e-02  3.32529903e-02\n",
      " -2.45233025e-03  3.83147770e-02 -2.60985536e-02  4.87952509e-02\n",
      "  1.79225847e-02  1.84859971e-02  1.24734131e-02 -5.41341986e-02\n",
      " -2.36471291e-02  2.96053396e-02 -3.45217009e-02  1.83466488e-02\n",
      " -4.67157572e-02  9.07483799e-02 -1.68580188e-02  2.28349267e-02\n",
      "  1.79983995e-02  2.31206442e-02  3.19640424e-03  4.48604405e-04\n",
      " -1.62939917e-02 -3.59482383e-02 -4.44718530e-02 -3.69551197e-03\n",
      " -4.37432761e-02 -3.05328800e-02  3.90679978e-02  1.48311542e-02\n",
      "  8.47428532e-02 -1.81579336e-02 -2.21765238e-02 -4.05170838e-02\n",
      " -6.04691529e-02 -3.00600928e-02  1.74157799e-02  4.98699212e-02\n",
      "  4.73615524e-02 -6.24683992e-02  2.90324743e-02  3.09367175e-02\n",
      "  3.65881429e-02 -4.99564793e-02  1.03202876e-02  5.58256738e-02\n",
      "  3.47860443e-02 -6.30716832e-04  2.06445568e-02 -7.00541834e-02\n",
      " -6.91308604e-02 -2.20891314e-02  4.20024765e-02 -3.80796606e-03\n",
      " -2.47016310e-02  6.01912469e-02 -7.19663977e-02 -1.54927921e-02\n",
      " -1.23080296e-03 -3.06172870e-02 -4.20768739e-03 -2.22056087e-02\n",
      "  6.55382008e-02  4.69544570e-02 -2.01087178e-02  3.27012892e-02\n",
      "  4.27076334e-02  5.14926857e-02 -2.51986553e-02 -6.36749488e-03\n",
      "  2.38294126e-02 -1.05177776e-02 -1.40917128e-02  1.27652332e-02\n",
      " -1.12103054e-02  1.06495382e-02 -5.80083454e-02  6.32696322e-02\n",
      "  8.64123946e-02  1.57329960e-02 -1.85196421e-02  1.67242557e-03\n",
      "  1.55139096e-02 -2.50139494e-02  1.85069638e-02 -7.13248882e-03\n",
      " -2.07141531e-02 -7.87119293e-03  3.58903954e-02 -2.91239645e-02\n",
      " -3.19073050e-03  3.30804513e-02 -2.10636164e-02  6.17160319e-03\n",
      " -3.71514311e-02  4.92541075e-02  1.39203025e-02  7.03144105e-03\n",
      "  7.29482731e-02 -4.29775918e-03 -5.23236436e-03  3.72226948e-03]\n"
     ]
    }
   ],
   "source": [
    "# Omzetten van teksten naar vectoren\n",
    "vectors = embedder.encode_documents(chunks)\n",
    "\n",
    "# Een kijkje nemen naar de eerste vector = chunk 1\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd7d95",
   "metadata": {},
   "source": [
    "### **6. Vectoren in database stoppen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e6b22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_count': 17, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'cost': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"../milvus.db\")\n",
    "\n",
    "# Formatteer de vectoren als een lijst van dictionaries\n",
    "data = [ {\"text\": text, \"vector\": vector, \"id\": id} for id, (text, vector) in enumerate(zip(chunks, vectors)) ]\n",
    "\n",
    "# Vectoren toevoegen aan de blogpost collectie\n",
    "client.insert(\"blogpost\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1ef0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4459f",
   "metadata": {},
   "source": [
    "## **Vector database bevragen** *(= Retrieval)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc64ed",
   "metadata": {},
   "source": [
    "### **6. Vraag embedden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f2b5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Wat kan je me vertellen over de blogpost?\"\n",
    "\n",
    "question_vector = embedder.encode_queries([question])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb247a",
   "metadata": {},
   "source": [
    "### **7. Relevante documenten zoeken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419ba18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultaten:\n",
      "{'id': 0, 'distance': 0.43110722303390503, 'entity': {'text': 'Blogpost\\nHoe maak je AI-modellen klein en \\nefficiënt?\\nAI-modellen worden steeds krachtiger, maar vaak ook steeds groter. Grote \\nmodellen vereisen veel rekenkracht, geheugen en energie - wat ze minder \\ngeschikt maakt voor gebruik op edge devices, maar ook realtime computervisie \\napplicaties zoals de Howest Virtual Mirror. Gelukkig zijn er diverse technieken \\nom AI-modellen te verkleinen zonder de accuraatheid ervan te verlagen. In \\ndeze blogpost bespreken we de belangrijkste optimalisatiestrategieën: \\nquanti'}}\n",
      "{'id': 1, 'distance': 0.4102115035057068, 'entity': {'text': 'inen zonder de accuraatheid ervan te verlagen. In \\ndeze blogpost bespreken we de belangrijkste optimalisatiestrategieën: \\nquantisatie, distillatie, pruning en meer. We bekijken ook welke tools je kunt \\ngebruiken, op welke platformen ze draaien, en hoe groot de impact kan zijn.\\n1. Quantisatie\\nInleiding\\nBinnenin een AI model zitten er miljoenen tot miljarden kommagetallen - ook \\nwel “gewichtenˮ en “activatiesˮ genoemd. Elk getal neemt typisch 32 bits \\n(nullen en enen) geheugen in beslag.\\nVoor een computer zij'}}\n",
      "{'id': 9, 'distance': 0.33616670966148376, 'entity': {'text': ' die weinig bijdragen aan het \\nuiteindelijke resultaat ervan. Het verminderen van overbodige parameters \\nverkleint het aantal berekeningen die moeten gemaakt worden waardoor het \\nmodel sneller zal zijn.\\nEr bestaan twee soorten pruning:\\nNiet-gestructureerde pruning: verwijderen van individuele gewichten of \\nverbindingen.\\nGestructureerde pruning: verwijderen van hele filters, neuronen of lagen.\\nBlogpost\\n3\\nOok hier kan je het model hertrainen of finetunen na het prunen om het kleine \\nverlies in accuraatheid te'}}\n",
      "{'id': 16, 'distance': 0.3301771879196167, 'entity': {'text': 'putervisie en taalmodellen maken ze het \\nverschil.\\nHet vergt wel enige tijd om mee te experimenteren en het verlies in \\naccuraatheid te beoordelen en/of te compenseren. Deze extra ontwikkelingstijd \\nkan afhankelijk van de schaal van het project al dan niet de moeite waard zijn.\\nBlogpost\\n5\\n'}}\n",
      "{'id': 13, 'distance': 0.3223533034324646, 'entity': {'text': 'elt gedistilleerde taalmodellen aan \\nzoals DeepSeek-R1\\ue088Distill-Qwen-7B (https://huggingface.co/deepseek-\\nai/DeepSeek-R1\\ue088Distill-Qwen-7B\\ue082. Een ouder succesverhaal van distillatie is \\nTinyBERT. Die is ruim 7 keer kleiner en 9 keer sneller dan het oorspronkelijke \\nBERT terwijl het slecht een daling van ±3% heeft in nauwkeurigheid \\n(https://arxiv.org/pdf/1909.10351\\ue082.\\nSamenvatting\\nBlogpost\\n4\\nOptimalisatietechnieken kunnen een sterk voordeel bieden op vlak van \\nsnelheid, energieconsumptie, kostprijs, hardware bep'}}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"../milvus.db\")\n",
    "\n",
    "results = client.search(\n",
    "    collection_name=\"blogpost\",\n",
    "    data=[question_vector],\n",
    "    output_fields=[\"text\"]\n",
    ")\n",
    "\n",
    "print(\"Resultaten:\")\n",
    "for result in results[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc56f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831ff41",
   "metadata": {},
   "source": [
    "## **Antwoord formuleren** *(= Generation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994945ce",
   "metadata": {},
   "source": [
    "### **8. Taalmodel bevragen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c492f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deze blogpost behandelt hoe AI-modellen kunnen worden gemaakt en geoptimaliseerd om kleiner en efficiënter te zijn. De focus ligt op verschillende optimalisatiestrategieën zoals quantisatie, distillatie, pruning en meer. Het doel is om de accuraatheid van het model te behouden terwijl het gebruik van resources wordt verminderd.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Je bent een professionele assistent. Gebruik onderstaande context om de vraag te beantwoorden.\n",
    "Als het antwoord niet in de context staat, zeg dan dat je het niet weet.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Vraag:\n",
    "{question}\n",
    "\n",
    "### Antwoord:\n",
    "\"\"\"\n",
    "\n",
    "def vraag_ollama_rag(context, question, model=\"llama3\"):\n",
    "    response = chat(model=model, messages=[{\"role\": \"user\", \"content\": prompt_template.format(context=context, question=question)}])\n",
    "    return response.message.content.strip()\n",
    "\n",
    "# Chunks van gevonden documenten terug aan elkaar plakken om context te vormen\n",
    "context = \"\\n\\n\".join([result.entity.text.strip() for result in results[0]])\n",
    "\n",
    "# Vraag stellen aan Ollama met de context en de vraag\n",
    "answer = vraag_ollama_rag(context, question)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa9696",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05c577",
   "metadata": {},
   "source": [
    "## **Verificatie**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfab37",
   "metadata": {},
   "source": [
    "### **9. Installeer guardrails-ai**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1950a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting guardrails-ai\n",
      "  Downloading guardrails_ai-0.6.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click<8.2.0 (from guardrails-ai)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting diff-match-patch<20241101,>=20230430 (from guardrails-ai)\n",
      "  Downloading diff_match_patch-20241021-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting faker<38.0.0,>=25.2.0 (from guardrails-ai)\n",
      "  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting guardrails-api-client<0.5.0,>=0.4.0 (from guardrails-ai)\n",
      "  Downloading guardrails_api_client-0.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting guardrails-hub-types<0.1.0,>=0.0.4 (from guardrails-ai)\n",
      "  Downloading guardrails_hub_types-0.0.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from guardrails-ai)\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (4.25.1)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (0.3.76)\n",
      "Collecting litellm<2.0.0,>=1.37.14 (from guardrails-ai)\n",
      "  Downloading litellm-1.77.3-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting lxml<7.0.0,>=4.9.3 (from guardrails-ai)\n",
      "  Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting openai<2.0.0,>=1.30.1 (from guardrails-ai)\n",
      "  Downloading openai-1.108.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from guardrails-ai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.24.0 (from guardrails-ai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (1.37.0)\n",
      "Requirement already satisfied: pip>=22 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (25.2)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.0.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (2.11.9)\n",
      "Collecting pydash<9.0.0,>=7.0.6 (from guardrails-ai)\n",
      "  Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting pyjwt<3.0.0,>=2.8.0 (from guardrails-ai)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (2.32.5)\n",
      "Collecting rich<15.0.0,>=13.6.0 (from guardrails-ai)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rstr<4.0.0,>=3.2.2 (from guardrails-ai)\n",
      "  Downloading rstr-3.2.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting semver<4.0.0,>=3.0.2 (from guardrails-ai)\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.1.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (8.5.0)\n",
      "Collecting tiktoken<1.0.0,>=0.5.1 (from guardrails-ai)\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting typer<0.16,>=0.9.0 (from guardrails-ai)\n",
      "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.8.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-ai) (4.15.0)\n",
      "Requirement already satisfied: tzdata in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from faker<38.0.0,>=25.2.0->guardrails-ai) (2025.2)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=2.1.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from guardrails-api-client<0.5.0,>=0.4.0->guardrails-ai) (2.5.0)\n",
      "Collecting lazy-imports<2,>=1 (from guardrails-api-client<0.5.0,>=0.4.0->guardrails-ai)\n",
      "  Downloading lazy_imports-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (0.27.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: idna in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (3.10)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai) (3.0.0)\n",
      "Collecting rfc3339-validator (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>0.1.0 (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (0.4.28)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (25.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.12.15)\n",
      "Collecting fastuuid>=0.12.0 (from litellm<2.0.0,>=1.37.14->guardrails-ai)\n",
      "  Downloading fastuuid-0.12.0-cp313-cp313-manylinux_2_34_x86_64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (8.7.0)\n",
      "Collecting jinja2<4.0.0,>=3.1.2 (from litellm<2.0.0,>=1.37.14->guardrails-ai)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pondpond<2.0.0,>=1.4.1 (from litellm<2.0.0,>=1.37.14->guardrails-ai)\n",
      "  Downloading pondpond-1.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (1.1.1)\n",
      "Requirement already satisfied: tokenizers in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.30.1->guardrails-ai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.30.1->guardrails-ai)\n",
      "  Downloading jiter-0.11.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.67.1)\n",
      "Requirement already satisfied: certifi in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.75.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.15 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.37.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (6.32.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->guardrails-ai) (0.58b0)\n",
      "Collecting madoka>=0.7.1 (from pondpond<2.0.0,>=1.4.1->litellm<2.0.0,>=1.37.14->guardrails-ai)\n",
      "  Downloading madoka-0.7.1.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.2->guardrails-ai) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (3.4.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<15.0.0,>=13.6.0->guardrails-ai)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from rich<15.0.0,>=13.6.0->guardrails-ai) (2.19.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.5.1->guardrails-ai) (2025.9.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.16,>=0.9.0->guardrails-ai)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from aiohttp>=3.10->litellm<2.0.0,>=1.37.14->guardrails-ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from aiohttp>=3.10->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from aiohttp>=3.10->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from aiohttp>=3.10->litellm<2.0.0,>=1.37.14->guardrails-ai) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from aiohttp>=3.10->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from aiohttp>=3.10->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.20.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.1->guardrails-ai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.1->guardrails-ai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.1->guardrails-ai) (0.25.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->guardrails-ai)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading lark-1.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]<5.0.0,>=4.22.0->guardrails-ai)\n",
      "  Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.35.0)\n",
      "Requirement already satisfied: filelock in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jens/anaconda3/envs/paai_workshop/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.1.10)\n",
      "Downloading guardrails_ai-0.6.7-py3-none-any.whl (235 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading diff_match_patch-20241021-py3-none-any.whl (43 kB)\n",
      "Downloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading guardrails_api_client-0.4.0-py3-none-any.whl (110 kB)\n",
      "Downloading guardrails_hub_types-0.0.4-py3-none-any.whl (36 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading lazy_imports-1.0.1-py3-none-any.whl (18 kB)\n",
      "Downloading litellm-1.77.3-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.108.2-py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.4/948.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading pondpond-1.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading rstr-3.2.2-py3-none-any.whl (10 kB)\n",
      "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "Downloading fastuuid-0.12.0-cp313-cp313-manylinux_2_34_x86_64.whl (278 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Downloading lark-1.3.0-py3-none-any.whl (113 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20250822-py3-none-any.whl (17 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: madoka\n",
      "\u001b[33m  DEPRECATION: Building 'madoka' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'madoka'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for madoka (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for madoka: filename=madoka-0.7.1-cp313-cp313-linux_x86_64.whl size=126665 sha256=32fff39729ea4513ab292a47e8746ad486357d75643520abc90f1a380fed502c\n",
      "  Stored in directory: /home/jens/.cache/pip/wheels/21/55/75/880e38c3bba4104134e8a71486b033d3530dcfd4de03423118\n",
      "Successfully built madoka\n",
      "Installing collected packages: madoka, webcolors, uri-template, types-python-dateutil, shellingham, semver, rstr, rfc3986-validator, rfc3339-validator, pyjwt, pydash, pondpond, opentelemetry-proto, mdurl, lxml, lazy-imports, lark, jsonref, jiter, jinja2, guardrails-hub-types, fqdn, fastuuid, faker, distro, diff-match-patch, click, tiktoken, rfc3987-syntax, opentelemetry-exporter-otlp-proto-common, markdown-it-py, arrow, rich, openai, isoduration, guardrails-api-client, typer, litellm, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, guardrails-ai\n",
      "\u001b[2K  Attempting uninstall: click━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [faker]id]etry-proto]\n",
      "\u001b[2K    Found existing installation: click 8.3.0m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [faker]\n",
      "\u001b[2K    Uninstalling click-8.3.0:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [faker]\n",
      "\u001b[2K      Successfully uninstalled click-8.3.090m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/41\u001b[0m [faker]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/41\u001b[0m [guardrails-ai]rails-ai]lm]ls-api-client]common]\n",
      "\u001b[1A\u001b[2KSuccessfully installed arrow-1.3.0 click-8.1.8 diff-match-patch-20241021 distro-1.9.0 faker-37.8.0 fastuuid-0.12.0 fqdn-1.5.1 guardrails-ai-0.6.7 guardrails-api-client-0.4.0 guardrails-hub-types-0.0.4 isoduration-20.11.0 jinja2-3.1.6 jiter-0.11.0 jsonref-1.1.0 lark-1.3.0 lazy-imports-1.0.1 litellm-1.77.3 lxml-6.0.2 madoka-0.7.1 markdown-it-py-4.0.0 mdurl-0.1.2 openai-1.108.2 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-exporter-otlp-proto-http-1.37.0 opentelemetry-proto-1.37.0 pondpond-1.4.1 pydash-8.0.5 pyjwt-2.10.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rich-14.1.0 rstr-3.2.2 semver-3.0.4 shellingham-1.5.4 tiktoken-0.11.0 typer-0.15.4 types-python-dateutil-2.9.0.20250822 uri-template-1.3.0 webcolors-24.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758632508.834696  133009 backup_poller.cc:139] Run client channel backup poller: UNKNOWN:pollset_work {children:[UNKNOWN:epoll_wait: Bad file descriptor (9)]}\n",
      "Enable anonymous metrics reporting? [Y/n]: ^C\n",
      "\u001b[31mAborted.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:guardrails-cli:Invalid URI! The package URI must start with 'hub://'\n"
     ]
    }
   ],
   "source": [
    "%pip install guardrails-ai\n",
    "!guardrails configure\n",
    "!guardrails hub install hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a2066",
   "metadata": {},
   "source": [
    "### **10. Installeer de RestrictToTopic validator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!guardrails hub install hub://tryolabs/restricttotopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c638306",
   "metadata": {},
   "source": [
    "### **11. Maak een Guard object aan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da0042",
   "metadata": {},
   "source": [
    "from guardrails import Guard\n",
    "from guardrails.hub import RestrictToTopic\n",
    "\n",
    "guard = Guard().use(\n",
    "    RestrictToTopic(\n",
    "        valid_topics=[\"AI\"],\n",
    "        invalid_topics=[\"sports\"]\n",
    "        disable_classifier=True,\n",
    "        disable_llm=False,\n",
    "        on_fail=\"filter\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a70a9",
   "metadata": {},
   "source": [
    "### **12. Gebruik de guard om response van het model te valideren** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d5f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_step = guard.validate(answer)\n",
    "\n",
    "# Print validated response\n",
    "if validation_step.validation_passed:\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"Validation Failed\", validation_step.validation_summaries[0].failure_reason)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paai_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

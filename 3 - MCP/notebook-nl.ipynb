{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0959318",
   "metadata": {},
   "source": [
    "# **Model Context Protocol**\n",
    "\n",
    "_Het Model Context Protocol of MCP - uitgevonden door Anthropic - is een gestandaardiseerde manier om taalmodellen toegang te geven tot bepaalde tools om acties uit te voeren. Nadat OpenAI dit open-source framework ook is beginnen gebruiken, werd het universeel geadopteerd als het standaard communicatieprotocol voor agents en LLM's. Vaak wordt MCP beschreven als de \"USB-C poort van taalmodellen\"._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d60ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1c5c4",
   "metadata": {},
   "source": [
    "## **Voorbereiding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6526d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastmcp\n",
      "  Downloading fastmcp-2.12.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting langchain_mcp_adapters\n",
      "  Downloading langchain_mcp_adapters-0.1.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting authlib>=1.5.2 (from fastmcp)\n",
      "  Downloading authlib-1.6.4-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting cyclopts>=3.0.0 (from fastmcp)\n",
      "  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting exceptiongroup>=1.2.2 (from fastmcp)\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from fastmcp) (0.28.1)\n",
      "Collecting mcp<2.0.0,>=1.12.4 (from fastmcp)\n",
      "  Downloading mcp-1.14.1-py3-none-any.whl.metadata (75 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openapi-core>=0.19.5 (from fastmcp)\n",
      "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting openapi-pydantic>=0.5.1 (from fastmcp)\n",
      "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pydantic>=2.11.7 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from pydantic[email]>=2.11.7->fastmcp) (2.11.9)\n",
      "Collecting pyperclip>=1.9.0 (from fastmcp)\n",
      "  Downloading pyperclip-1.10.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dotenv>=1.1.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from fastmcp) (1.1.1)\n",
      "Collecting rich>=13.9.4 (from fastmcp)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.36 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain_mcp_adapters) (0.3.76)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain_mcp_adapters) (4.15.0)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting cryptography (from authlib>=1.5.2->fastmcp)\n",
      "  Downloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: attrs>=23.1.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from cyclopts>=3.0.0->fastmcp) (25.3.0)\n",
      "Collecting docstring-parser>=0.15 (from cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (0.4.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (25.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp) (0.4.1)\n",
      "Collecting jsonschema>=4.20.0 (from mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp) (2.10.1)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting starlette>=0.27 (from mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting uvicorn>=0.31.1 (from mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting isodate (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting more-itertools (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting werkzeug<3.1.2 (from openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (0.4.1)\n",
      "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp)\n",
      "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.9.4->fastmcp)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from rich>=13.9.4->fastmcp) (2.19.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->fastmcp) (1.3.1)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (3.0.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3.36->langchain_mcp_adapters) (0.25.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting docutils (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp)\n",
      "  Downloading docutils-0.22.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting click>=7.0 (from uvicorn>=0.31.1->mcp<2.0.0,>=1.12.4->fastmcp)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug<3.1.2->openapi-core>=0.19.5->fastmcp)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography->authlib>=1.5.2->fastmcp)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography->authlib>=1.5.2->fastmcp)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp) (2.5.0)\n",
      "Requirement already satisfied: six in /home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages (from rfc3339-validator->openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp) (1.17.0)\n",
      "Downloading fastmcp-2.12.3-py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_mcp_adapters-0.1.10-py3-none-any.whl (15 kB)\n",
      "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading authlib-1.6.4-py2.py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mcp-1.14.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyperclip-1.10.0-py3-none-any.whl (11 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
      "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.22.2-py3-none-any.whl (632 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyperclip, parse, xxhash, rpds-py, rfc3339-validator, python-multipart, pycparser, pathable, ormsgpack, more-itertools, mdurl, MarkupSafe, lazy-object-proxy, isodate, exceptiongroup, docutils, docstring-parser, dnspython, click, werkzeug, uvicorn, starlette, sse-starlette, referencing, markdown-it-py, email-validator, cffi, rich, openapi-pydantic, langgraph-sdk, jsonschema-specifications, jsonschema-path, cryptography, rich-rst, jsonschema, authlib, openapi-schema-validator, mcp, langgraph-checkpoint, cyclopts, openapi-spec-validator, langgraph-prebuilt, langchain_mcp_adapters, openapi-core, langgraph, fastmcp\n",
      "Successfully installed MarkupSafe-3.0.2 authlib-1.6.4 cffi-2.0.0 click-8.3.0 cryptography-46.0.1 cyclopts-3.24.0 dnspython-2.8.0 docstring-parser-0.17.0 docutils-0.22.2 email-validator-2.3.0 exceptiongroup-1.3.0 fastmcp-2.12.3 isodate-0.7.2 jsonschema-4.25.1 jsonschema-path-0.3.4 jsonschema-specifications-2025.9.1 langchain_mcp_adapters-0.1.10 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 lazy-object-proxy-1.12.0 markdown-it-py-4.0.0 mcp-1.14.1 mdurl-0.1.2 more-itertools-10.8.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 ormsgpack-1.10.0 parse-1.20.2 pathable-0.4.4 pycparser-2.23 pyperclip-1.10.0 python-multipart-0.0.20 referencing-0.36.2 rfc3339-validator-0.1.4 rich-14.1.0 rich-rst-1.3.1 rpds-py-0.27.1 sse-starlette-3.0.2 starlette-0.48.0 uvicorn-0.37.0 werkzeug-3.1.1 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fastmcp langchain_mcp_adapters langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772e84e",
   "metadata": {},
   "source": [
    "## **MCP server**\n",
    "\n",
    "Voor de mensen die REST API's met HTTP endpoints kennen: MCP is hier een equivalent van maar dan met \"tools\". <br>\n",
    "\n",
    "**Tools zijn acties** die iets **berekenen of uitvoeren** in opdracht van de LLM. <br>\n",
    "We hebben dus een computer of **MCP server** nodig die luistert naar binnenkomende instructies en deze uitvoert. <br>\n",
    "Welke tools er allemaal beschikbaar zijn en wat ze precies doen, wordt allemaal gedefinieerd op deze server. <br>\n",
    "\n",
    "Er bestaan al veel **publieke MCP servers** die je kan gebruiken, bv. om het weerbericht op te vragen. <br>\n",
    "Om de focus van deze workshop bij **privacy** te houden, gaan wij zelf Ã©Ã©n maken en hosten. <br>\n",
    "\n",
    "Neem een kijkje naar de code van `mcp-server.py`. Probeer te beschrijven wat elke functie doet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa65be92",
   "metadata": {},
   "source": [
    "**Start de MCP server** door het commando uit te voeren in de terminal:\n",
    "\n",
    "```bash\n",
    "python \"3 - MCP/mcp-server.py\"\n",
    "```\n",
    "<img src=\"../.github/fastmcp.png\" alt=\"FastMCP\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784387b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31458936",
   "metadata": {},
   "source": [
    "## **MCP client**\n",
    "\n",
    "Nu de server met onze tools draait, kunnen **MCP clients** ermee connecteren. <br>\n",
    "Een client kan ook perfect met meerdere servers connecteren, dan heeft deze toegang tot de tools van alle servers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed1761",
   "metadata": {},
   "source": [
    "### **1. Python script als client**\n",
    "Een MCP client is typisch een taalmodel, maar we kunnen ook d.m.v. een Python script **manueel ermee verbinden** en tools aanspreken. <br>\n",
    "Dit kan handig zijn om te **testen** of de server en zijn tools goed werken, alvorens we er een LLM op loslaten. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31949497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "config = {\n",
    "    \"mcpServers\": {\n",
    "        \"private\": {\"url\": \"http://localhost:8000/sse\"},    # Onze eigen lokale MCP server\n",
    "    },\n",
    "}\n",
    "\n",
    "client = Client(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3949027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tools:\n",
      "  - sum: Use this tool to calculate the sum of two numbers.\n",
      "  - multiply: Use this tool to calculate the product of two numbers.\n",
      "  - datetime: Use this tool to get the current date and time.\n",
      "  - search_files: Use this tool to search for relevant information in the user's files and documents. Provide a search query or keywords to this tool.\n",
      "\n",
      "Resources:\n",
      "\n",
      "Prompts:\n",
      "[./Blogpost.pdf - pagina 2]\n",
      "Voorbeelden: op Ollama kan je van sommige taalmodellen - zoals de gemma3 \n",
      "familie - ook QAT-varianten terugvinden die tot 3 keer sneller zijn \n",
      "(https://ollama.com/library/gemma3î‚’4b-it-qat). Ook van computervisie \n",
      "modellen zoals YOLO bestaan PTQ-varianten zoals YOLOv8î‚ˆDetection-\n",
      "Quantized (https://huggingface.co/qualcomm/YOLOv8î‚ˆDetection-Quantized).\n",
      "Frameworks\n",
      "Er bestaan verschillende Python-libraries die functies bevatten om jouw model \n",
      "te quantiseren:\n",
      "\n",
      "[./Blogpost.pdf - pagina 4]\n",
      "zoals DeepSeek-R1î‚ˆDistill-Qwen-7B (https://huggingface.co/deepseek-\n",
      "ai/DeepSeek-R1î‚ˆDistill-Qwen-7Bî‚‚. Een ouder succesverhaal van distillatie is \n",
      "TinyBERT. Die is ruim 7 keer kleiner en 9 keer sneller dan het oorspronkelijke \n",
      "BERT terwijl het slecht een daling van Â±3% heeft in nauwkeurigheid \n",
      "(https://arxiv.org/pdf/1909.10351î‚‚.\n",
      "Samenvatting\n",
      "Blogpost\n",
      "4\n",
      "\n",
      "[./Blogpost.pdf - pagina 4]\n",
      "Ook hier kan je het model hertrainen of finetunen na het prunen om het kleine \n",
      "verlies in accuraatheid te compenseren.\n",
      "Frameworks\n",
      "Er bestaan Python-libraries die functies bevatten om jouw model te prunen:\n",
      "Gebruik de â€œtorch.nn.utils.pruneË® library voor PyTorch modellen.\n",
      "Gebruik de â€œtensorflow_model_optimization.sparsity.kerasË® library voor \n",
      "TensorFlow modellen.\n",
      "Ook Hugging FaceÊ¼s Optimum library beschikt over pruning mogelijkheden \n",
      "voor Intel-systemen.\n",
      "3. Kennisdistillatie\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async with client:\n",
    "    \n",
    "    print(\"\\nTools:\")\n",
    "    tools = await client.list_tools()\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}: {tool.description}\")\n",
    "        \n",
    "    print(\"\\nResources:\")\n",
    "    resources = await client.list_resources()\n",
    "    for resource in resources:\n",
    "        print(f\"  - {resource.name}: {resource.description}\")\n",
    "\n",
    "    print(\"\\nPrompts:\")\n",
    "    prompts = await client.list_prompts()\n",
    "    for prompt in prompts:\n",
    "        print(f\"  - {prompt.name}: {prompt.description}\")\n",
    "\n",
    "    a = 5\n",
    "    b = 3\n",
    "    result = await client.call_tool(\"search_files\", {\"question\": f\"What can you tell me about blogpost.pdf?\"})\n",
    "    print(result.content[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069c387",
   "metadata": {},
   "source": [
    "### **2. Taalmodel als client**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a51453",
   "metadata": {},
   "source": [
    "Nu gaan we een taalmodel toegang geven tot de tools op onze MCP server. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004cb1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workshop-private-agentic-ai/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "client = MultiServerMCPClient({\"private\": {\"url\": \"http://localhost:8000/sse\", \"transport\": \"sse\"}})\n",
    "tools = await client.get_tools()\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "agent = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1899e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™â€â™‚ï¸ User:\tWhat are some optimization strategies I could use to reduce the size of AI models?\n",
      "ğŸ¤– Calling tool(s) search_files\n",
      "ğŸ¤– Milvus:\tBased on the information provided in the blog post, there are several optimization strategies you could use to reduce the size of AI models:\n",
      "\n",
      "1. **Pruning**: This involves removing elements from the model that contribute little to the final result. There are two types of pruning:\n",
      "\t* Non-structured pruning: Removing individual weights or connections.\n",
      "\t* Structured pruning: Removing entire filters, neurons, or layers.\n",
      "2. **Knowledge Distillation**: This involves transferring knowledge from a large teacher model to a smaller student model.\n",
      "3. **Quantization**: This involves reducing the precision of model weights and activations to reduce memory usage.\n",
      "\n",
      "Additionally, there are Python libraries available for these tasks:\n",
      "\n",
      "* PyTorch: torch.nn.utils.prune\n",
      "* TensorFlow: tensorflow_model_optimization.sparsity.keras\n",
      "* Hugging Face's Optimum library (for Intel systems)\n",
      "\n",
      "It's worth noting that some models have already been optimized for size and can be found on platforms like Ollama, such as the Gemma3 family of language models.\n",
      "ğŸ¤– Milvus:\tGoodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "\n",
    "history = []\n",
    "history.append({\"role\": \"system\", \"content\": \"Your name is Milvus, you are a helpful assistant that answers questions. You have access to some tools to assist you. If you fetch context from the user's files, always include the source in your answer.\"})\n",
    "\n",
    "while True:\n",
    "    question = input(\"Type your next question (/bye to stop): \")\n",
    "    if question.strip().lower() == \"/bye\":\n",
    "        print(\"ğŸ¤– Milvus:\\tGoodbye!\")\n",
    "        break\n",
    "    if not question.strip():\n",
    "        continue\n",
    "    \n",
    "    print(f\"ğŸ™â€â™‚ï¸ User:\\t{question}\")\n",
    "    history.append({\"role\": \"user\", \"content\": question})\n",
    "    outputs = await agent.ainvoke({\"messages\": history})\n",
    "    \n",
    "    for output in outputs[\"messages\"]:\n",
    "        if isinstance(output, AIMessage):\n",
    "            if output.tool_calls:\n",
    "                print(f\"ğŸ¤– Calling tool(s) {', '.join(tc['name'] for tc in output.tool_calls)}\")\n",
    "        #elif isinstance(output, ToolMessage):\n",
    "            # print(f\"ğŸ› ï¸ Tool:\\t{output.content}\")\n",
    "            \n",
    "    answer = outputs[\"messages\"][-1].content\n",
    "    print(f\"ğŸ¤– Milvus:\\t{answer}\")\n",
    "    history.append({\"role\": \"assistant\", \"content\": answer})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
